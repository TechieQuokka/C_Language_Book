# 14.1 정렬 알고리즘 (Sorting Algorithms)

## 핵심 개념: 순서의 수학과 비교의 철학

정렬은 **"무질서에서 질서로"**의 변환을 구현하는 가장 기본적이면서도 핵심적인 알고리즘입니다. 이는 단순히 데이터를 배열하는 것을 넘어서 **비교 이론(Comparison Theory)**, **정보 이론(Information Theory)**, **최적화 이론(Optimization Theory)**의 교차점에 위치한 깊이 있는 수학적 문제입니다.

### 정렬의 수학적 기초: 전순서 관계

#### 전순서의 공리적 정의

정렬 가능한 집합 S에서 관계 ≤는 다음을 만족해야 합니다:

1. **반사적(Reflexive)**: ∀a ∈ S, a ≤ a
2. **이행적(Transitive)**: ∀a,b,c ∈ S, (a ≤ b ∧ b ≤ c) → a ≤ c
3. **반대칭적(Antisymmetric)**: ∀a,b ∈ S, (a ≤ b ∧ b ≤ a) → a = b
4. **완전성(Totality)**: ∀a,b ∈ S, (a ≤ b ∨ b ≤ a)

**철학적 의미**: 정렬은 단순한 배열이 아니라 **"질서 있는 우주"**의 구현입니다.

#### 비교 기반 정렬의 정보 이론적 한계

**정리**: n개 원소의 비교 기반 정렬에서 최악의 경우 필요한 비교 횟수는 Ω(n log n)입니다.

**증명**:
- n개 원소의 가능한 순열: n!
- 각 비교는 최대 2가지 결과 → k번 비교로 최대 2^k가지 경우 구별
- 모든 순열 구별하려면: 2^k ≥ n!
- 스털링 근사: log₂(n!) ≈ n log₂(n) - n log₂(e)
- 따라서: k ≥ n log₂(n) - n log₂(e) = Ω(n log n)

**정보 이론적 해석**: 이는 **엔트로피의 물리 법칙**과 같은 근본적 한계입니다.

### 정렬 알고리즘의 분류학

#### 안정성 (Stability)
**안정적 정렬**: 동일한 키를 가진 원소들의 상대적 순서 보존
- **수학적 정의**: ∀i < j, key(aᵢ) = key(aⱼ) → sorted_position(aᵢ) < sorted_position(aⱼ)

#### 적응성 (Adaptivity)
**적응적 정렬**: 입력 데이터의 기존 순서를 활용하여 성능 향상
- **측정**: 역순 쌍(inversion) 개수에 따른 시간 복잡도 변화

#### 메모리 사용 패턴
- **In-place**: O(1) 추가 공간
- **Out-of-place**: O(n) 추가 공간

## 기본 정렬 알고리즘: 단순함의 아름다움

### 버블 정렬: 물리학적 직관의 구현

#### 알고리즘의 물리적 모델
버블 정렬은 **"부력의 원리"**를 모방합니다. 가벼운 원소(작은 값)가 위로 떠오르는 자연스러운 과정입니다.

```c
void bubbleSort(int arr[], int n) {
    for (int i = 0; i < n - 1; i++) {
        bool swapped = false;

        // 각 패스에서 가장 큰 원소가 맨 뒤로 "부상"
        for (int j = 0; j < n - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                // 인접한 원소들의 교환
                int temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
                swapped = true;
            }
        }

        // 최적화: 교환이 없으면 정렬 완료
        if (!swapped) break;
    }
}
```

#### 수학적 분석
- **최악 시간 복잡도**: O(n²) - 역순 배열
- **최선 시간 복잡도**: O(n) - 이미 정렬된 배열 (최적화된 버전)
- **평균 시간 복잡도**: O(n²)
- **공간 복잡도**: O(1)
- **안정성**: 안정적

**역순 쌍 개수**: 최악의 경우 C(n,2) = n(n-1)/2

### 선택 정렬: 최적화의 욕심

#### 욕심쟁이 알고리즘의 철학
선택 정렬은 **"매 단계에서 최선의 선택"**을 하는 욕심쟁이 알고리즘입니다.

```c
void selectionSort(int arr[], int n) {
    for (int i = 0; i < n - 1; i++) {
        int minIndex = i;

        // 남은 배열에서 최솟값 찾기
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }

        // 최솟값을 올바른 위치로 이동
        if (minIndex != i) {
            int temp = arr[i];
            arr[i] = arr[minIndex];
            arr[minIndex] = temp;
        }
    }
}
```

#### 교환 횟수의 최적성
**정리**: 선택 정렬은 교환 횟수를 최소화합니다.
- **최대 교환 횟수**: n-1 (다른 O(n²) 알고리즘은 O(n²) 교환)
- **응용**: 교환 비용이 매우 큰 경우 유리

### 삽입 정렬: 인간적 직관의 알고리즘

#### 카드 정렬의 자연스러운 모방
삽입 정렬은 인간이 카드를 정렬하는 방식을 모방한 가장 직관적인 알고리즘입니다.

```c
void insertionSort(int arr[], int n) {
    for (int i = 1; i < n; i++) {
        int key = arr[i];
        int j = i - 1;

        // key보다 큰 원소들을 한 칸씩 뒤로 이동
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j--;
        }

        // key를 올바른 위치에 삽입
        arr[j + 1] = key;
    }
}
```

#### 적응성의 수학적 분석
삽입 정렬의 시간 복잡도는 **역순 쌍의 개수**에 비례합니다:
- **역순 쌍(Inversion)**: (i,j) s.t. i < j and arr[i] > arr[j]
- **수행 시간**: O(n + I), 여기서 I는 역순 쌍의 개수
- **최선**: O(n) - 이미 정렬된 경우
- **최악**: O(n²) - 역순 정렬된 경우

**적응성 지수**: T(n,I) = O(n + I)

## 고급 정렬 알고리즘: 분할 정복의 우아함

### 병합 정렬: 분할 정복의 완벽한 구현

#### 분할 정복 패러다임
병합 정렬은 **"큰 문제를 작은 문제로 나누어 해결"**하는 분할 정복 알고리즘의 교과서적 예시입니다.

```c
void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;

    // 임시 배열 생성
    int* L = (int*)malloc(n1 * sizeof(int));
    int* R = (int*)malloc(n2 * sizeof(int));

    // 데이터 복사
    for (int i = 0; i < n1; i++)
        L[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[mid + 1 + j];

    // 병합 과정
    int i = 0, j = 0, k = left;

    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }

    // 남은 원소들 복사
    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }

    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }

    free(L);
    free(R);
}

void mergeSort(int arr[], int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;

        // 분할
        mergeSort(arr, left, mid);
        mergeSort(arr, mid + 1, right);

        // 정복
        merge(arr, left, mid, right);
    }
}
```

#### 마스터 정리를 통한 복잡도 분석
**점화식**: T(n) = 2T(n/2) + O(n)

마스터 정리 적용:
- a = 2, b = 2, f(n) = O(n)
- log_b(a) = log₂(2) = 1
- f(n) = O(n^1) = O(n^log_b(a))
- **결론**: T(n) = O(n log n)

#### 안정성의 보장
병합 과정에서 `<=` 비교를 사용함으로써 안정성을 보장합니다.

### 퀵 정렬: 확률론적 우아함

#### 분할의 예술
퀵 정렬은 **"피벗을 중심으로 한 지능적 분할"**을 통해 평균적으로 최적의 성능을 달성합니다.

```c
int partition(int arr[], int low, int high) {
    int pivot = arr[high];  // 마지막 원소를 피벗으로 선택
    int i = low - 1;        // 작은 원소들의 인덱스

    for (int j = low; j < high; j++) {
        // 현재 원소가 피벗보다 작거나 같으면
        if (arr[j] <= pivot) {
            i++;
            // 교환
            int temp = arr[i];
            arr[i] = arr[j];
            arr[j] = temp;
        }
    }

    // 피벗을 올바른 위치에 배치
    int temp = arr[i + 1];
    arr[i + 1] = arr[high];
    arr[high] = temp;

    return i + 1;
}

void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);

        // 피벗을 기준으로 분할하여 재귀 호출
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
```

#### 확률론적 분석
**평균 시간 복잡도**: O(n log n)
**최악 시간 복잡도**: O(n²) - 이미 정렬된 배열에서 마지막 원소를 피벗으로 선택

**기댓값 분석**:
- 좋은 분할 확률: 1/2 (피벗이 중간 50% 범위에 있을 때)
- 평균 분할 깊이: O(log n)
- 각 레벨에서 총 작업량: O(n)

#### 랜덤화된 퀵 정렬
```c
void randomizedQuickSort(int arr[], int low, int high) {
    if (low < high) {
        // 랜덤 피벗 선택
        int randomIndex = low + rand() % (high - low + 1);

        // 랜덤 원소를 마지막으로 이동
        int temp = arr[randomIndex];
        arr[randomIndex] = arr[high];
        arr[high] = temp;

        int pi = partition(arr, low, high);

        randomizedQuickSort(arr, low, pi - 1);
        randomizedQuickSort(arr, pi + 1, high);
    }
}
```

**확률론적 보장**: 모든 입력에 대해 기댓값 O(n log n)

### 힙 정렬: 완전 이진 트리의 활용

#### 힙 자료구조의 수학적 성질
힙 정렬은 **완전 이진 트리**의 성질을 활용한 우아한 알고리즘입니다.

```c
void heapify(int arr[], int n, int i) {
    int largest = i;        // 루트를 가장 큰 값으로 초기화
    int left = 2 * i + 1;   // 왼쪽 자식
    int right = 2 * i + 2;  // 오른쪽 자식

    // 왼쪽 자식이 루트보다 크면
    if (left < n && arr[left] > arr[largest])
        largest = left;

    // 오른쪽 자식이 현재 가장 큰 값보다 크면
    if (right < n && arr[right] > arr[largest])
        largest = right;

    // 가장 큰 값이 루트가 아니면
    if (largest != i) {
        int temp = arr[i];
        arr[i] = arr[largest];
        arr[largest] = temp;

        // 서브 트리를 재귀적으로 힙화
        heapify(arr, n, largest);
    }
}

void heapSort(int arr[], int n) {
    // 힙 구성 (재배열)
    for (int i = n / 2 - 1; i >= 0; i--)
        heapify(arr, n, i);

    // 힙에서 원소를 하나씩 추출
    for (int i = n - 1; i > 0; i--) {
        // 현재 루트를 끝으로 이동
        int temp = arr[0];
        arr[0] = arr[i];
        arr[i] = temp;

        // 줄어든 힙에 대해 다시 힙화
        heapify(arr, i, 0);
    }
}
```

#### 힙 구성의 시간 복잡도
**정리**: 배열을 힙으로 만드는 것은 O(n) 시간에 가능합니다.

**증명**:
- 높이 h인 노드는 최대 ⌈n/2^(h+1)⌉개
- 각 노드에서 heapify 비용: O(h)
- 총 비용: Σ(h=0 to log n) ⌈n/2^(h+1)⌉ × h ≤ n × Σ(h=0 to ∞) h/2^h = n × 2 = O(n)

**기하급수의 합**: Σ(h=1 to ∞) h/2^h = 2

## 선형 시간 정렬: 비교의 한계를 넘어서

### 계수 정렬: 분포의 활용

#### 알고리즘의 철학
계수 정렬은 **"빈도수 계산을 통한 위치 결정"**이라는 독창적 접근을 사용합니다.

```c
void countingSort(int arr[], int n, int max_val) {
    // 계수 배열 초기화
    int* count = (int*)calloc(max_val + 1, sizeof(int));
    int* output = (int*)malloc(n * sizeof(int));

    // 각 원소의 개수 세기
    for (int i = 0; i < n; i++)
        count[arr[i]]++;

    // 누적 합 계산 (위치 정보 생성)
    for (int i = 1; i <= max_val; i++)
        count[i] += count[i - 1];

    // 출력 배열 구성 (안정성 보장을 위해 뒤에서부터)
    for (int i = n - 1; i >= 0; i--) {
        output[count[arr[i]] - 1] = arr[i];
        count[arr[i]]--;
    }

    // 결과를 원본 배열에 복사
    for (int i = 0; i < n; i++)
        arr[i] = output[i];

    free(count);
    free(output);
}
```

#### 시간 복잡도 분석
- **시간 복잡도**: O(n + k), 여기서 k는 입력 범위
- **공간 복잡도**: O(k)
- **제약 조건**: k = O(n)일 때만 효율적

### 기수 정렬: 자릿수의 마법

#### 다단계 안정 정렬의 원리
기수 정렬은 **"안정한 정렬을 여러 번 적용"**하여 전체 정렬을 달성합니다.

```c
int getMax(int arr[], int n) {
    int max = arr[0];
    for (int i = 1; i < n; i++)
        if (arr[i] > max)
            max = arr[i];
    return max;
}

void countingSortForRadix(int arr[], int n, int exp) {
    int output[n];
    int count[10] = {0};

    // 현재 자릿수에 대한 개수 세기
    for (int i = 0; i < n; i++)
        count[(arr[i] / exp) % 10]++;

    // 누적 합 계산
    for (int i = 1; i < 10; i++)
        count[i] += count[i - 1];

    // 출력 배열 구성
    for (int i = n - 1; i >= 0; i--) {
        output[count[(arr[i] / exp) % 10] - 1] = arr[i];
        count[(arr[i] / exp) % 10]--;
    }

    // 결과 복사
    for (int i = 0; i < n; i++)
        arr[i] = output[i];
}

void radixSort(int arr[], int n) {
    int max = getMax(arr, n);

    // 각 자릿수에 대해 계수 정렬 수행
    for (int exp = 1; max / exp > 0; exp *= 10)
        countingSortForRadix(arr, n, exp);
}
```

#### 기수 정렬의 수학적 분석
- **시간 복잡도**: O(d × (n + k))
  - d: 최대 자릿수
  - k: 각 자릿수의 범위 (보통 10)
- **정수의 경우**: d = O(log n) → O(n log n)
- **고정 길이 문자열**: d = 상수 → O(n)

**핵심 통찰**: 자릿수가 상수일 때 선형 시간 달성 가능

### 버킷 정렬: 분산의 힘

#### 균등 분포 가정의 활용
버킷 정렬은 **"입력이 균등 분포"**라는 가정 하에 평균 선형 시간을 달성합니다.

```c
void bucketSort(float arr[], int n) {
    // 버킷 배열 생성
    int bucket_count = n;
    float** buckets = (float**)malloc(bucket_count * sizeof(float*));
    int* bucket_sizes = (int*)calloc(bucket_count, sizeof(int));

    // 각 버킷 초기화
    for (int i = 0; i < bucket_count; i++) {
        buckets[i] = (float*)malloc(n * sizeof(float));
    }

    // 원소들을 버킷에 분배
    for (int i = 0; i < n; i++) {
        int bucket_index = (int)(arr[i] * bucket_count);
        buckets[bucket_index][bucket_sizes[bucket_index]++] = arr[i];
    }

    // 각 버킷을 개별적으로 정렬
    for (int i = 0; i < bucket_count; i++) {
        qsort(buckets[i], bucket_sizes[i], sizeof(float),
              (int(*)(const void*, const void*))compare);
    }

    // 정렬된 버킷들을 연결
    int index = 0;
    for (int i = 0; i < bucket_count; i++) {
        for (int j = 0; j < bucket_sizes[i]; j++) {
            arr[index++] = buckets[i][j];
        }
    }

    // 메모리 해제
    for (int i = 0; i < bucket_count; i++) {
        free(buckets[i]);
    }
    free(buckets);
    free(bucket_sizes);
}
```

#### 확률론적 분석
**가정**: 입력이 [0,1) 구간에서 균등 분포

**기댓값 분석**:
- 각 버킷의 기댓값 크기: 1
- 한 버킷의 정렬 시간: O(1²) = O(1)
- 전체 시간 복잡도: O(n)

**분산 분석**: 버킷 크기는 이항 분포 B(n, 1/n)을 따름

## 하이브리드 정렬 알고리즘: 실용성의 극치

### Introsort: 최악의 경우 보장

#### 다중 패러다임의 조합
Introsort는 **퀸 정렬 + 힙 정렬 + 삽입 정렬**의 장점을 결합합니다.

```c
void introsortUtil(int arr[], int begin, int end, int depthLimit) {
    int size = end - begin;

    // 작은 배열은 삽입 정렬
    if (size < 16) {
        insertionSort(arr + begin, size);
        return;
    }

    // 재귀 깊이 제한 초과 시 힙 정렬
    if (depthLimit == 0) {
        heapSort(arr + begin, size);
        return;
    }

    // 일반적인 경우 퀵 정렬
    int pivot = partition(arr, begin, end - 1);
    introsortUtil(arr, begin, pivot, depthLimit - 1);
    introsortUtil(arr, pivot + 1, end, depthLimit - 1);
}

void introsort(int arr[], int n) {
    int depthLimit = 2 * (int)log2(n);
    introsortUtil(arr, 0, n, depthLimit);
}
```

#### 복잡도 보장
- **최악 시간 복잡도**: O(n log n) - 힙 정렬로 보장
- **평균 시간 복잡도**: O(n log n) - 퀵 정렬의 성능
- **최선 시간 복잡도**: O(n) - 거의 정렬된 경우 삽입 정렬

### Timsort: 실제 데이터의 패턴 활용

#### 적응성의 극대화
Timsort는 **실제 데이터의 패턴**을 극대한 활용하는 고도로 최적화된 알고리즘입니다.

**핵심 아이디어**:
1. **Run 탐지**: 이미 정렬된 부분 수열 찾기
2. **최소 Run 길이**: 효율성을 위한 최소 길이 보장
3. **병합 스택**: 균형 잡힌 병합을 위한 스택 관리
4. **갤로핑 모드**: 한쪽이 연속으로 승리할 때 최적화

```c
#define MIN_MERGE 32

int getMinRunLength(int n) {
    int r = 0;
    while (n >= MIN_MERGE) {
        r |= (n & 1);
        n >>= 1;
    }
    return n + r;
}

// 자연스러운 Run 찾기
int findRun(int arr[], int start, int end) {
    if (start == end) return start + 1;

    int runEnd = start + 1;

    // 상승 또는 하강 순서 판단
    if (arr[start] <= arr[start + 1]) {
        // 상승 순서
        while (runEnd < end && arr[runEnd - 1] <= arr[runEnd])
            runEnd++;
    } else {
        // 하강 순서 - 뒤집어야 함
        while (runEnd < end && arr[runEnd - 1] > arr[runEnd])
            runEnd++;

        // 하강 부분을 뒤집어서 상승으로 만듦
        reverse(arr, start, runEnd - 1);
    }

    return runEnd;
}
```

#### 성능 특성
- **최악 시간 복잡도**: O(n log n)
- **최선 시간 복잡도**: O(n) - 이미 정렬된 경우
- **실제 데이터**: 대부분의 경우 O(n) 또는 O(n log n)보다 훨씬 빠름

## 정렬 알고리즘의 선택 기준

### 성능 특성 매트릭스

| 알고리즘 | 최선 | 평균 | 최악 | 공간 | 안정성 | 적응성 |
|---------|------|------|------|------|--------|--------|
| 버블 정렬 | O(n) | O(n²) | O(n²) | O(1) | 안정 | 적응적 |
| 선택 정렬 | O(n²) | O(n²) | O(n²) | O(1) | 불안정 | 비적응적 |
| 삽입 정렬 | O(n) | O(n²) | O(n²) | O(1) | 안정 | 적응적 |
| 병합 정렬 | O(n log n) | O(n log n) | O(n log n) | O(n) | 안정 | 비적응적 |
| 퀵 정렬 | O(n log n) | O(n log n) | O(n²) | O(log n) | 불안정 | 비적응적 |
| 힙 정렬 | O(n log n) | O(n log n) | O(n log n) | O(1) | 불안정 | 비적응적 |
| 계수 정렬 | O(n+k) | O(n+k) | O(n+k) | O(k) | 안정 | 비적응적 |

### 선택 가이드라인

#### 입력 크기별 추천
- **n < 50**: 삽입 정렬
- **50 ≤ n < 1000**: 퀵 정렬 또는 힙 정렬
- **n ≥ 1000**: Introsort 또는 Timsort

#### 특수 상황별 추천
- **안정성 필요**: 병합 정렬, Timsort
- **메모리 제약**: 힙 정렬, 퀵 정렬
- **거의 정렬된 데이터**: 삽입 정렬, Timsort
- **정수, 제한된 범위**: 계수 정렬, 기수 정렬
- **실시간 시스템**: 힙 정렬 (보장된 O(n log n))

## 정렬의 응용과 확장

### 부분 정렬 (Partial Sorting)

#### k개의 최솟값 찾기
```c
// 퀵셀렉트 알고리즘을 이용한 k번째 작은 원소 찾기
int quickSelect(int arr[], int left, int right, int k) {
    if (left == right) return arr[left];

    int pivotIndex = partition(arr, left, right);
    int pivotRank = pivotIndex - left + 1;

    if (k == pivotRank) {
        return arr[pivotIndex];
    } else if (k < pivotRank) {
        return quickSelect(arr, left, pivotIndex - 1, k);
    } else {
        return quickSelect(arr, pivotIndex + 1, right, k - pivotRank);
    }
}
```

**평균 시간 복잡도**: O(n)

### 외부 정렬 (External Sorting)

#### 대용량 데이터 처리
메모리보다 큰 데이터를 정렬하는 기법:

1. **분할**: 메모리 크기만큼 청크로 나누어 개별 정렬
2. **병합**: k-way 병합으로 최종 결과 생성

```c
void externalSort(const char* inputFile, const char* outputFile,
                  int memorySize, int totalSize) {
    int numChunks = (totalSize + memorySize - 1) / memorySize;

    // Phase 1: 청크별 정렬
    for (int i = 0; i < numChunks; i++) {
        // 청크 읽기
        int* chunk = readChunk(inputFile, i, memorySize);
        int chunkSize = min(memorySize, totalSize - i * memorySize);

        // 내부 정렬
        quickSort(chunk, 0, chunkSize - 1);

        // 임시 파일에 저장
        writeChunk(chunk, i, chunkSize);
        free(chunk);
    }

    // Phase 2: k-way 병합
    kWayMerge(numChunks, outputFile);
}
```

### 안정 정렬의 구현

#### 불안정 알고리즘을 안정하게 만들기
```c
typedef struct {
    int value;
    int originalIndex;
} StableElement;

int stableCompare(const void* a, const void* b) {
    StableElement* elemA = (StableElement*)a;
    StableElement* elemB = (StableElement*)b;

    if (elemA->value != elemB->value) {
        return elemA->value - elemB->value;
    }

    // 값이 같으면 원래 인덱스로 비교
    return elemA->originalIndex - elemB->originalIndex;
}
```

## 마무리: 정렬 알고리즘의 철학적 의의

정렬 알고리즘은 **"컴퓨터 과학의 축소판"**입니다:

### 정렬의 수학적 아름다움
- **이론적 한계**: 정보 이론적 하한선 Ω(n log n)
- **최적 알고리즘**: 이론적 한계에 도달하는 실용적 알고리즘들
- **특수 경우**: 추가 정보 활용 시 선형 시간 달성

### 정렬의 공학적 지혜
- **트레이드오프**: 시간, 공간, 안정성, 적응성 간의 균형
- **하이브리드 접근**: 여러 알고리즘의 장점을 결합한 실용적 해결책
- **실제 데이터**: 이론과 실제의 차이를 메우는 적응적 최적화

**핵심 통찰**: 정렬은 단순한 배열이 아니라 **"질서 창조의 예술"**입니다. 무작위성에서 질서를 찾아내고, 혼돈에서 패턴을 발견하는 인간의 근본적 욕구를 알고리즘으로 구현한 것입니다.

**철학적 결론**: 완벽한 정렬 알고리즘은 존재하지 않습니다. 각 알고리즘은 특정 상황에서의 **"최선의 선택"**일 뿐입니다. 이는 공학에서 **"모든 것을 위한 해결책은 없고, 특정 문제를 위한 최적해만 있다"**는 중요한 교훈을 보여줍니다.