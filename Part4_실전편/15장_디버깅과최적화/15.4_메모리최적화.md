# 15.4 메모리 최적화

## 개념 정리

### 메모리 계층구조와 성능

현대 컴퓨터 시스템에서 메모리는 **속도와 비용에 따른 계층구조**를 형성합니다. 메모리 최적화의 핵심은 이 계층구조를 이해하고 **빠른 메모리의 활용도를 최대화**하는 것입니다.

#### 메모리 계층구조

```
CPU 레지스터      │  1 cycle     │  32-64 bytes   │  가장 빠름
L1 캐시          │  1-3 cycles  │  32-64 KB      │  매우 빠름
L2 캐시          │  10-20 cycles│  256KB-1MB     │  빠름
L3 캐시          │  20-40 cycles│  8-32MB        │  보통
메인 메모리(RAM)  │  200-300     │  4-64GB        │  느림
SSD             │  수만 cycles  │  256GB-4TB     │  매우 느림
HDD             │  수십만      │  1TB-16TB      │  가장 느림
```

#### 메모리 지역성 원리

**1. 시간적 지역성 (Temporal Locality)**
- **개념**: 최근에 접근한 데이터를 다시 접근할 가능성이 높음
- **활용**: 자주 사용되는 데이터를 캐시에 유지
- **예시**: 루프 변수, 함수 지역변수

**2. 공간적 지역성 (Spatial Locality)**
- **개념**: 접근한 데이터 근처의 데이터를 접근할 가능성이 높음
- **활용**: 연속된 메모리 블록을 캐시로 로드
- **예시**: 배열 순차 접근, 구조체 멤버 접근

#### 캐시 동작 원리

**캐시 라인 (Cache Line)**:
- **크기**: 일반적으로 64바이트
- **특징**: 메모리는 캐시 라인 단위로 로드됨
- **영향**: 연속된 데이터 접근이 효율적

**캐시 미스 유형**:
1. **Cold Miss**: 처음 접근하는 데이터
2. **Capacity Miss**: 캐시 용량 부족으로 인한 교체
3. **Conflict Miss**: 캐시 매핑 충돌

### 메모리 접근 패턴 최적화

#### 1. 순차 접근 vs 랜덤 접근

**성능 차이 이해**:
```c
// 순차 접근 (캐시 친화적)
for (int i = 0; i < size; i++) {
    sum += array[i]; // 예측 가능한 패턴
}

// 랜덤 접근 (캐시 비친화적)
for (int i = 0; i < size; i++) {
    sum += array[random_indices[i]]; // 예측 불가능한 패턴
}
```

**성능 차이 원인**:
- 순차 접근: **캐시 프리패칭** 효과로 미래 데이터 미리 로드
- 랜덤 접근: 매번 **캐시 미스** 발생 가능성 높음

#### 2. 메모리 스트라이드 최적화

**스트라이드 개념**:
- **Unit Stride**: 연속된 메모리 접근 (가장 효율적)
- **Constant Stride**: 일정 간격 메모리 접근
- **Random Stride**: 불규칙한 간격 접근 (가장 비효율적)

**다차원 배열 접근 최적화**:
```c
// 2차원 배열 [rows][cols]
int matrix[1000][1000];

// 비효율적: 열 우선 접근 (큰 스트라이드)
for (int j = 0; j < cols; j++) {        // 열 인덱스 먼저
    for (int i = 0; i < rows; i++) {    // 행 인덱스 나중
        sum += matrix[i][j];            // 캐시 라인 미스 빈발
    }
}

// 효율적: 행 우선 접근 (Unit Stride)
for (int i = 0; i < rows; i++) {        // 행 인덱스 먼저
    for (int j = 0; j < cols; j++) {    // 열 인덱스 나중
        sum += matrix[i][j];            // 캐시 라인 히트 빈발
    }
}
```

#### 3. 블록 기반 접근 (Cache Blocking)

**개념**: 캐시 크기에 맞는 블록 단위로 데이터 처리

**행렬 곱셈 최적화**:
```c
void matrix_multiply_blocked(double A[][N], double B[][N], double C[][N]) {
    int block_size = 64; // L1 캐시 크기에 맞게 조정

    for (int ii = 0; ii < N; ii += block_size) {
        for (int jj = 0; jj < N; jj += block_size) {
            for (int kk = 0; kk < N; kk += block_size) {

                // 블록 경계 계산
                int i_end = min(ii + block_size, N);
                int j_end = min(jj + block_size, N);
                int k_end = min(kk + block_size, N);

                // 블록 내부 계산 (캐시 친화적)
                for (int i = ii; i < i_end; i++) {
                    for (int j = jj; j < j_end; j++) {
                        for (int k = kk; k < k_end; k++) {
                            C[i][j] += A[i][k] * B[k][j];
                        }
                    }
                }
            }
        }
    }
}
```

### 데이터 구조 최적화

#### 1. Array of Structures vs Structure of Arrays

**AoS (Array of Structures)**:
```c
typedef struct {
    float x, y, z;    // 위치
    float vx, vy, vz; // 속도
    float mass;       // 질량
    int id;          // 식별자
} Particle;

Particle particles[1000];

// 위치만 업데이트하는 경우
for (int i = 0; i < 1000; i++) {
    particles[i].x += particles[i].vx * dt;
    particles[i].y += particles[i].vy * dt;
    particles[i].z += particles[i].vz * dt;
    // mass, id는 사용하지 않지만 캐시에 로드됨
}
```

**SoA (Structure of Arrays)**:
```c
typedef struct {
    float x[1000], y[1000], z[1000];    // 위치 배열들
    float vx[1000], vy[1000], vz[1000]; // 속도 배열들
    float mass[1000];                   // 질량 배열
    int id[1000];                      // 식별자 배열
} ParticleSystem;

ParticleSystem particles;

// 위치만 업데이트하는 경우 (메모리 효율적)
for (int i = 0; i < 1000; i++) {
    particles.x[i] += particles.vx[i] * dt;
    particles.y[i] += particles.vy[i] * dt;
    particles.z[i] += particles.vz[i] * dt;
    // 필요한 데이터만 캐시에 로드됨
}
```

**선택 기준**:
- **AoS**: 개별 객체 단위 처리가 많은 경우
- **SoA**: 특정 속성만 일괄 처리하는 경우 (벡터화에도 유리)

#### 2. 구조체 멤버 정렬 최적화

**메모리 정렬 원리**:
- CPU는 **정렬된 주소**에서 데이터를 더 효율적으로 읽음
- **패딩(Padding)**: 컴파일러가 정렬을 위해 빈 공간 추가

**비효율적인 구조체**:
```c
struct BadStruct {
    char c1;      // 1바이트
    int i;        // 4바이트 (3바이트 패딩 추가됨)
    char c2;      // 1바이트
    double d;     // 8바이트 (7바이트 패딩 추가됨)
    char c3;      // 1바이트 (7바이트 패딩 추가됨)
}; // 총 32바이트 (실제 데이터는 14바이트)
```

**최적화된 구조체**:
```c
struct GoodStruct {
    double d;     // 8바이트 (가장 큰 타입 먼저)
    int i;        // 4바이트
    char c1;      // 1바이트
    char c2;      // 1바이트
    char c3;      // 1바이트
    // 1바이트 패딩
}; // 총 16바이트 (50% 절약)
```

**수동 패딩 제어**:
```c
struct PackedStruct {
    char c1;
    int i;
    char c2;
} __attribute__((packed)); // 패딩 강제 제거 (정렬 성능 희생)

struct AlignedStruct {
    char data[63];
} __attribute__((aligned(64))); // 캐시 라인 정렬
```

### 메모리 할당 최적화

#### 1. 메모리 풀 (Memory Pool)

**개념**: 미리 큰 메모리 블록을 할당한 후 작은 단위로 분할 사용

**장점**:
- **할당/해제 속도**: O(1) 시간 복잡도
- **메모리 단편화 방지**: 연속된 메모리 사용
- **캐시 지역성**: 관련 객체들이 메모리에서 가까이 위치

**기본 메모리 풀 구현**:
```c
typedef struct {
    void* memory;           // 전체 메모리 블록
    size_t block_size;      // 각 블록 크기
    size_t block_count;     // 총 블록 개수
    void* free_list;        // 자유 블록 연결 리스트
    size_t allocated;       // 할당된 블록 수
} MemoryPool;

MemoryPool* create_pool(size_t block_size, size_t block_count) {
    MemoryPool* pool = malloc(sizeof(MemoryPool));

    // 블록 크기를 포인터 크기로 정렬
    block_size = (block_size + sizeof(void*) - 1) & ~(sizeof(void*) - 1);

    pool->memory = malloc(block_size * block_count);
    pool->block_size = block_size;
    pool->block_count = block_count;
    pool->allocated = 0;

    // 자유 리스트 초기화
    char* ptr = (char*)pool->memory;
    pool->free_list = ptr;

    for (size_t i = 0; i < block_count - 1; i++) {
        *(void**)ptr = ptr + block_size;
        ptr += block_size;
    }
    *(void**)ptr = NULL; // 마지막 블록

    return pool;
}

void* pool_alloc(MemoryPool* pool) {
    if (pool->free_list == NULL) return NULL;

    void* block = pool->free_list;
    pool->free_list = *(void**)block;
    pool->allocated++;

    return block;
}

void pool_free(MemoryPool* pool, void* block) {
    *(void**)block = pool->free_list;
    pool->free_list = block;
    pool->allocated--;
}
```

#### 2. 스택 할당자 (Stack Allocator)

**개념**: LIFO(Last In, First Out) 순서로 메모리 할당/해제

**특징**:
- **매우 빠른 할당**: 포인터 이동만으로 할당
- **일괄 해제**: 스택 포인터 리셋으로 전체 해제
- **용도**: 임시 데이터, 함수 지역 배열 대체

```c
typedef struct {
    void* memory;
    size_t size;
    size_t offset;
    size_t peak_usage; // 최대 사용량 추적
} StackAllocator;

StackAllocator* create_stack_allocator(size_t size) {
    StackAllocator* allocator = malloc(sizeof(StackAllocator));
    allocator->memory = malloc(size);
    allocator->size = size;
    allocator->offset = 0;
    allocator->peak_usage = 0;
    return allocator;
}

void* stack_alloc(StackAllocator* allocator, size_t size) {
    // 정렬 (8바이트 경계)
    size = (size + 7) & ~7;

    if (allocator->offset + size > allocator->size) {
        return NULL; // 메모리 부족
    }

    void* ptr = (char*)allocator->memory + allocator->offset;
    allocator->offset += size;

    if (allocator->offset > allocator->peak_usage) {
        allocator->peak_usage = allocator->offset;
    }

    return ptr;
}

void stack_reset(StackAllocator* allocator) {
    allocator->offset = 0; // 전체 메모리 해제
}
```

#### 3. 커스텀 할당자 전략

**크기별 분류 할당자**:
```c
#define SIZE_CLASSES 8

typedef struct {
    MemoryPool* pools[SIZE_CLASSES];
    size_t size_limits[SIZE_CLASSES];
} SizeClassAllocator;

void init_size_class_allocator(SizeClassAllocator* allocator) {
    // 크기 클래스: 8, 16, 32, 64, 128, 256, 512, 1024 바이트
    for (int i = 0; i < SIZE_CLASSES; i++) {
        size_t size = 8 << i;
        allocator->size_limits[i] = size;
        allocator->pools[i] = create_pool(size, 1000);
    }
}

void* size_class_alloc(SizeClassAllocator* allocator, size_t size) {
    // 적절한 크기 클래스 찾기
    for (int i = 0; i < SIZE_CLASSES; i++) {
        if (size <= allocator->size_limits[i]) {
            return pool_alloc(allocator->pools[i]);
        }
    }
    // 큰 할당은 시스템 malloc 사용
    return malloc(size);
}
```

### 캐시 최적화 기법

#### 1. False Sharing 방지

**False Sharing 개념**:
- 서로 다른 변수가 같은 캐시 라인에 위치
- 한 변수 수정 시 다른 변수의 캐시도 무효화
- 멀티스레드 환경에서 성능 저하 원인

**문제가 되는 코드**:
```c
struct {
    int counter1; // 스레드 1이 수정
    int counter2; // 스레드 2가 수정
} shared_data; // 같은 캐시 라인에 위치할 가능성
```

**해결책**:
```c
struct {
    int counter1;
    char padding[64 - sizeof(int)]; // 캐시 라인 크기만큼 패딩
} thread1_data __attribute__((aligned(64)));

struct {
    int counter2;
    char padding[64 - sizeof(int)];
} thread2_data __attribute__((aligned(64)));
```

#### 2. 데이터 프리패칭

**소프트웨어 프리패칭**:
```c
#include <xmmintrin.h> // SSE

void optimized_loop(int* data, int size) {
    const int prefetch_distance = 8; // 프리패치 거리

    for (int i = 0; i < size; i++) {
        // 미래 데이터 미리 로드
        if (i + prefetch_distance < size) {
            _mm_prefetch(&data[i + prefetch_distance], _MM_HINT_T0);
        }

        // 현재 데이터 처리
        data[i] = data[i] * 2 + 1;
    }
}
```

#### 3. 캐시 라인 정렬

**정렬의 중요성**:
```c
// 캐시 라인 정렬된 구조체
typedef struct {
    int data[16]; // 64바이트 = 1 캐시 라인
} __attribute__((aligned(64))) CacheAlignedStruct;

// 배열도 캐시 라인 정렬
int aligned_array[1024] __attribute__((aligned(64)));
```

### 메모리 사용량 최적화

#### 1. 비트 필드 활용

**메모리 절약을 위한 비트 필드**:
```c
// 일반적인 구조체 (20바이트)
struct RegularFlags {
    int active;      // 4바이트
    int visible;     // 4바이트
    int selected;    // 4바이트
    int type;        // 4바이트
    int priority;    // 4바이트
};

// 비트 필드 사용 (4바이트)
struct CompactFlags {
    unsigned int active   : 1;  // 1비트
    unsigned int visible  : 1;  // 1비트
    unsigned int selected : 1;  // 1비트
    unsigned int type     : 8;  // 8비트 (0-255)
    unsigned int priority : 5;  // 5비트 (0-31)
    unsigned int reserved : 16; // 예약 비트
}; // 총 32비트 = 4바이트
```

**비트 필드 주의사항**:
- **접근 성능**: 비트 연산으로 인한 오버헤드
- **포터빌리티**: 컴파일러별 차이
- **원자성**: 멀티스레드에서 문제 가능

#### 2. 문자열 인터닝 (String Interning)

**개념**: 동일한 문자열을 한 번만 저장하고 포인터로 공유

```c
typedef struct StringPool {
    char** strings;
    size_t count;
    size_t capacity;
} StringPool;

const char* intern_string(StringPool* pool, const char* str) {
    // 기존 문자열 검색
    for (size_t i = 0; i < pool->count; i++) {
        if (strcmp(pool->strings[i], str) == 0) {
            return pool->strings[i]; // 기존 문자열 반환
        }
    }

    // 새 문자열 추가
    char* new_str = strdup(str);
    // pool에 추가 로직...

    return new_str;
}
```

#### 3. Copy-on-Write 구현

**개념**: 실제 수정이 발생하기 전까지 복사를 지연

```c
typedef struct {
    char* data;
    size_t size;
    int ref_count;
    int is_cow; // Copy-on-Write 플래그
} COWString;

COWString* cow_copy(COWString* original) {
    original->ref_count++;
    return original; // 실제 복사 없이 참조만 증가
}

void cow_write(COWString* str, size_t index, char value) {
    if (str->ref_count > 1) {
        // 실제 복사 수행
        char* new_data = malloc(str->size);
        memcpy(new_data, str->data, str->size);

        str->ref_count--;
        str->data = new_data;
        str->ref_count = 1;
    }

    str->data[index] = value;
}
```

### 메모리 프로파일링과 분석

#### 1. 메모리 사용량 분석 도구

**Valgrind Massif**:
```bash
# 힙 프로파일링
valgrind --tool=massif ./program

# 결과 시각화
ms_print massif.out.[pid]
```

**AddressSanitizer**:
```bash
# 메모리 오류 및 누수 검출
gcc -fsanitize=address -g -o program source.c
./program
```

#### 2. 메모리 사용량 모니터링

**런타임 메모리 통계**:
```c
#include <sys/resource.h>

void print_memory_usage() {
    struct rusage usage;
    getrusage(RUSAGE_SELF, &usage);

    printf("최대 상주 메모리: %ld KB\n", usage.ru_maxrss);
    printf("페이지 폴트 (minor): %ld\n", usage.ru_minflt);
    printf("페이지 폴트 (major): %ld\n", usage.ru_majflt);
}
```

**힙 사용량 추적**:
```c
typedef struct {
    size_t total_allocated;
    size_t current_allocated;
    size_t peak_allocated;
    size_t allocation_count;
} MemoryStats;

static MemoryStats g_stats = {0};

void* tracked_malloc(size_t size) {
    void* ptr = malloc(size);
    if (ptr) {
        g_stats.total_allocated += size;
        g_stats.current_allocated += size;
        g_stats.allocation_count++;

        if (g_stats.current_allocated > g_stats.peak_allocated) {
            g_stats.peak_allocated = g_stats.current_allocated;
        }
    }
    return ptr;
}

void tracked_free(void* ptr, size_t size) {
    if (ptr) {
        free(ptr);
        g_stats.current_allocated -= size;
    }
}
```

### 플랫폼별 메모리 최적화

#### 1. NUMA 시스템 고려사항

**NUMA (Non-Uniform Memory Access)**:
- **특징**: 메모리 접근 시간이 위치에 따라 다름
- **최적화**: 프로세서와 가까운 메모리 사용

```c
#include <numa.h>

void numa_optimized_allocation() {
    if (numa_available() != -1) {
        // 현재 노드에 메모리 할당
        int node = numa_node_of_cpu(sched_getcpu());
        void* memory = numa_alloc_onnode(size, node);
    }
}
```

#### 2. 임베디드 시스템 최적화

**제한된 메모리 환경**:
- **정적 할당 선호**: 동적 할당 최소화
- **스택 사용량 제한**: 깊은 재귀 피하기
- **메모리 풀 활용**: 단편화 방지

```c
// 정적 메모리 풀
static char memory_pool[POOL_SIZE];
static size_t pool_offset = 0;

void* embedded_alloc(size_t size) {
    if (pool_offset + size > POOL_SIZE) {
        return NULL; // 메모리 부족
    }

    void* ptr = &memory_pool[pool_offset];
    pool_offset += size;
    return ptr;
}
```

### 메모리 최적화 검증

#### 1. 성능 측정

**캐시 성능 측정**:
```bash
# 캐시 미스율 측정
perf stat -e cache-misses,cache-references ./program

# 메모리 대역폭 측정
perf stat -e cpu/mem-loads/,cpu/mem-stores/ ./program
```

#### 2. 메모리 효율성 평가

**메모리 사용률 계산**:
```c
double calculate_memory_efficiency(size_t useful_data, size_t total_allocated) {
    return (double)useful_data / total_allocated * 100.0;
}

void analyze_data_structure_efficiency() {
    size_t array_memory = 1000 * sizeof(int);           // 4000 bytes
    size_t list_memory = 1000 * sizeof(ListNode);       // 16000 bytes (포인터 포함)

    printf("배열 효율성: %.1f%%\n",
           calculate_memory_efficiency(4000, array_memory));
    printf("연결리스트 효율성: %.1f%%\n",
           calculate_memory_efficiency(4000, list_memory));
}
```

이러한 체계적인 메모리 최적화 기법을 통해 C 프로그램의 메모리 효율성과 성능을 크게 향상시킬 수 있습니다.