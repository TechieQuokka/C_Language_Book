# 15.3 성능 최적화 기법

## 개념 정리

### 성능 최적화의 기본 원리

성능 최적화는 **프로그램의 실행 속도를 향상시키고 자원 사용량을 줄이는** 체계적인 과정입니다. 단순히 코드를 빠르게 만드는 것이 아니라, **측정 가능한 성능 향상**을 달성하는 것이 목표입니다.

#### 최적화의 핵심 원칙

**1. 측정 우선 원칙 (Measure First)**
```
"추측하지 말고 측정하라" - 성능 최적화의 황금률
```

- **프로파일링**: 실제 병목 지점 식별
- **벤치마킹**: 정량적 성능 평가
- **비교 분석**: 최적화 전후 성능 차이 측정

**2. 80/20 법칙 (Pareto Principle)**
- 전체 실행 시간의 **80%가 코드의 20%**에서 소모
- **핫스팟(Hot Spot)** 영역에 집중
- 전체적인 아키텍처 개선이 미시적 최적화보다 효과적

**3. 가독성과 성능의 균형**
- 과도한 최적화는 **코드 복잡성 증가**
- **유지보수성** 고려 필요
- 컴파일러 최적화 활용 우선

#### 성능 최적화 계층 구조

```
1. 알고리즘 최적화 (가장 높은 우선순위)
   └── 시간/공간 복잡도 개선

2. 데이터 구조 최적화
   └── 적절한 자료구조 선택

3. 컴파일러 최적화
   └── 컴파일러 옵션 활용

4. 코드 레벨 최적화
   └── 루프, 함수, 메모리 접근 최적화

5. 시스템 레벨 최적화 (가장 낮은 우선순위)
   └── 하드웨어 특성 활용
```

### 성능 측정과 분석

#### 1. 시간 복잡도 분석

**Big-O 표기법 실제 성능 영향**:

| 복잡도 | n=100 | n=1,000 | n=10,000 | 알고리즘 예시 |
|--------|-------|---------|----------|---------------|
| O(1) | 1 | 1 | 1 | 해시 테이블 접근 |
| O(log n) | 7 | 10 | 13 | 이진 탐색 |
| O(n) | 100 | 1,000 | 10,000 | 선형 탐색 |
| O(n log n) | 700 | 10,000 | 130,000 | 퀵정렬, 병합정렬 |
| O(n²) | 10,000 | 1,000,000 | 100,000,000 | 버블정렬 |

**실제 측정의 중요성**:
- 상수 인수(Constant Factor)의 영향
- 캐시 효과 및 메모리 지역성
- 작은 입력에서는 단순 알고리즘이 더 빠를 수 있음

#### 2. 프로파일링 도구

**gprof 사용법**:
```bash
# 프로파일링 정보 포함 컴파일
gcc -pg -O2 -o program source.c

# 프로그램 실행 (gmon.out 생성)
./program

# 프로파일 결과 분석
gprof program gmon.out > profile.txt
```

**결과 분석 포인트**:
- **Flat Profile**: 함수별 실행 시간
- **Call Graph**: 함수 호출 관계와 시간
- **Cumulative Time**: 하위 함수 포함 시간

**perf 도구 활용**:
```bash
# 성능 이벤트 수집
perf record ./program

# 결과 분석
perf report

# 특정 이벤트 모니터링
perf stat -e cycles,instructions,cache-misses ./program
```

#### 3. 벤치마킹 기법

**마이크로벤치마크 작성**:
```c
#include <time.h>
#include <sys/time.h>

double get_time() {
    struct timeval tv;
    gettimeofday(&tv, NULL);
    return tv.tv_sec + tv.tv_usec / 1000000.0;
}

double benchmark_function(void (*func)(), int iterations) {
    double start = get_time();
    for (int i = 0; i < iterations; i++) {
        func();
    }
    double end = get_time();
    return end - start;
}
```

**신뢰성 있는 벤치마킹**:
- **워밍업**: 캐시 로딩을 위한 사전 실행
- **반복 측정**: 여러 번 측정 후 평균/중간값 계산
- **노이즈 제거**: 시스템 부하 최소화 환경에서 측정

### 알고리즘 최적화

#### 1. 검색 알고리즘 최적화

**선형 검색 → 이진 검색**:
```c
// O(n) 선형 검색
int linear_search(int arr[], int n, int target) {
    for (int i = 0; i < n; i++) {
        if (arr[i] == target) return i;
    }
    return -1;
}

// O(log n) 이진 검색 (정렬된 배열 필요)
int binary_search(int arr[], int low, int high, int target) {
    while (low <= high) {
        int mid = low + (high - low) / 2;
        if (arr[mid] == target) return mid;
        if (arr[mid] < target) low = mid + 1;
        else high = mid - 1;
    }
    return -1;
}
```

**해시 테이블 활용**: O(1) 평균 검색 시간
```c
// 간단한 해시 함수
unsigned int hash(int key, int table_size) {
    return ((unsigned int)key) % table_size;
}
```

#### 2. 정렬 알고리즘 최적화

**성능 비교**:

| 알고리즘 | 평균 | 최악 | 최선 | 안정성 | 메모리 |
|----------|------|------|------|--------|--------|
| 버블정렬 | O(n²) | O(n²) | O(n) | 안정 | O(1) |
| 선택정렬 | O(n²) | O(n²) | O(n²) | 불안정 | O(1) |
| 삽입정렬 | O(n²) | O(n²) | O(n) | 안정 | O(1) |
| 퀵정렬 | O(n log n) | O(n²) | O(n log n) | 불안정 | O(log n) |
| 병합정렬 | O(n log n) | O(n log n) | O(n log n) | 안정 | O(n) |

**하이브리드 정렬 전략**:
```c
void optimized_sort(int arr[], int low, int high) {
    if (high - low < 10) {
        // 작은 배열: 삽입 정렬
        insertion_sort(arr, low, high);
    } else {
        // 큰 배열: 퀵 정렬
        quick_sort(arr, low, high);
    }
}
```

#### 3. 동적 계획법 적용

**피보나치 수열 최적화**:
```c
// O(2^n) - 지수적 복잡도
int fibonacci_naive(int n) {
    if (n <= 1) return n;
    return fibonacci_naive(n-1) + fibonacci_naive(n-2);
}

// O(n) - 동적 계획법
int fibonacci_dp(int n) {
    if (n <= 1) return n;

    int prev2 = 0, prev1 = 1;
    for (int i = 2; i <= n; i++) {
        int current = prev1 + prev2;
        prev2 = prev1;
        prev1 = current;
    }
    return prev1;
}
```

### 루프 최적화

#### 1. 루프 불변 코드 이동

**문제가 되는 패턴**:
```c
// 비효율적: 루프 내에서 반복 계산
for (int i = 0; i < n; i++) {
    result[i] = array[i] * (expensive_calculation() + constant);
}
```

**최적화**:
```c
// 효율적: 불변 계산을 루프 밖으로 이동
int computed_value = expensive_calculation() + constant;
for (int i = 0; i < n; i++) {
    result[i] = array[i] * computed_value;
}
```

**문자열 길이 계산 최적화**:
```c
// 비효율적: 매번 strlen 호출
for (int i = 0; i < strlen(str); i++) {
    process(str[i]);
}

// 효율적: 길이를 한 번만 계산
int len = strlen(str);
for (int i = 0; i < len; i++) {
    process(str[i]);
}
```

#### 2. 루프 언롤링 (Loop Unrolling)

**기본 개념**:
- 루프 오버헤드 감소
- 파이프라인 효율성 향상
- 컴파일러 최적화 기회 증가

**수동 언롤링 예시**:
```c
// 기본 루프
for (int i = 0; i < n; i++) {
    result[i] = array[i] * 2 + 1;
}

// 4배 언롤링
for (int i = 0; i < n-3; i += 4) {
    result[i] = array[i] * 2 + 1;
    result[i+1] = array[i+1] * 2 + 1;
    result[i+2] = array[i+2] * 2 + 1;
    result[i+3] = array[i+3] * 2 + 1;
}
// 나머지 처리
for (; i < n; i++) {
    result[i] = array[i] * 2 + 1;
}
```

**언롤링 고려사항**:
- **코드 크기 증가**: I-cache 미스 가능성
- **최적 언롤링 팩터**: 하드웨어 의존적
- **컴파일러 자동 최적화**: `-funroll-loops` 옵션

#### 3. 루프 퓨전 (Loop Fusion)

**개념**: 인접한 루프들을 하나로 결합하여 메모리 지역성 향상

**분리된 루프들**:
```c
// 세 번의 메모리 순회
for (int i = 0; i < n; i++) {
    array[i] *= 2;
}
for (int i = 0; i < n; i++) {
    array[i] += 1;
}
for (int i = 0; i < n; i++) {
    array[i] = (array[i] > 100) ? 100 : array[i];
}
```

**융합된 루프**:
```c
// 한 번의 메모리 순회
for (int i = 0; i < n; i++) {
    array[i] *= 2;
    array[i] += 1;
    array[i] = (array[i] > 100) ? 100 : array[i];
}
```

#### 4. 루프 블로킹 (Loop Tiling)

**개념**: 캐시 크기에 맞는 블록 단위로 처리하여 캐시 효율성 극대화

**행렬 곱셈 최적화**:
```c
// 기본 행렬 곱셈 (캐시 비친화적)
void matrix_multiply_basic(double A[][N], double B[][N], double C[][N]) {
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            for (int k = 0; k < N; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

// 블록 기반 행렬 곱셈 (캐시 친화적)
void matrix_multiply_blocked(double A[][N], double B[][N], double C[][N]) {
    int block_size = 64; // 캐시 크기에 맞게 조정

    for (int ii = 0; ii < N; ii += block_size) {
        for (int jj = 0; jj < N; jj += block_size) {
            for (int kk = 0; kk < N; kk += block_size) {
                // 블록 내부 계산
                for (int i = ii; i < min(ii + block_size, N); i++) {
                    for (int j = jj; j < min(jj + block_size, N); j++) {
                        for (int k = kk; k < min(kk + block_size, N); k++) {
                            C[i][j] += A[i][k] * B[k][j];
                        }
                    }
                }
            }
        }
    }
}
```

### 함수 최적화

#### 1. 인라인 함수 활용

**개념**: 함수 호출 오버헤드 제거

**적용 기준**:
- **작은 함수**: 1-3줄 정도
- **자주 호출되는 함수**: 루프 내부 등
- **성능 중요 경로**: 핫스팟 영역

```c
// 인라인 함수 정의
inline int max(int a, int b) {
    return (a > b) ? a : b;
}

// 컴파일러 힌트
__attribute__((always_inline)) int force_inline_func(int x) {
    return x * x + 1;
}
```

#### 2. 함수 포인터 최적화

**문제**: 간접 호출로 인한 성능 저하
**해결**: 조건부 컴파일이나 함수 포인터 배열 활용

```c
// 함수 포인터 배열로 분기 최적화
typedef int (*operation_func)(int, int);

int add(int a, int b) { return a + b; }
int subtract(int a, int b) { return a - b; }
int multiply(int a, int b) { return a * b; }

operation_func operations[] = {add, subtract, multiply};

int calculate(int op, int a, int b) {
    return operations[op](a, b); // 직접 호출보다 빠름
}
```

#### 3. 꼬리 재귀 최적화

**개념**: 재귀 호출을 반복문으로 변환

```c
// 일반 재귀 (스택 오버플로우 위험)
int factorial(int n) {
    if (n <= 1) return 1;
    return n * factorial(n - 1);
}

// 꼬리 재귀
int factorial_tail(int n, int acc) {
    if (n <= 1) return acc;
    return factorial_tail(n - 1, n * acc);
}

// 반복문으로 변환 (최적화)
int factorial_iterative(int n) {
    int result = 1;
    for (int i = 2; i <= n; i++) {
        result *= i;
    }
    return result;
}
```

### 분기 최적화

#### 1. 분기 예측 친화적 코드

**개념**: CPU의 분기 예측기 효율성 향상

**예측 가능한 패턴 작성**:
```c
// 예측하기 어려운 패턴
if (random_condition()) {
    // 50% 확률로 실행
}

// 예측하기 쉬운 패턴
if (likely_condition) {
    // 90% 확률로 실행
} else {
    // 10% 확률로 실행
}
```

**GCC 분기 예측 힌트**:
```c
#define likely(x)   __builtin_expect(!!(x), 1)
#define unlikely(x) __builtin_expect(!!(x), 0)

if (likely(ptr != NULL)) {
    // 일반적인 경우
    *ptr = value;
} else {
    // 예외적인 경우
    handle_error();
}
```

#### 2. 브랜치리스 프로그래밍

**조건부 할당 최적화**:
```c
// 분기 있는 버전
int max_with_branch(int a, int b) {
    if (a > b) return a;
    else return b;
}

// 브랜치리스 버전
int max_branchless(int a, int b) {
    return a + ((b - a) & ((b - a) >> 31));
}
```

**룩업 테이블 활용**:
```c
// 복잡한 분기문
int complex_calculation(int x) {
    if (x == 0) return 1;
    else if (x == 1) return 4;
    else if (x == 2) return 9;
    else if (x == 3) return 16;
    // ...
}

// 룩업 테이블
int lookup_table[] = {1, 4, 9, 16, 25, 36, ...};
int fast_calculation(int x) {
    return (x < TABLE_SIZE) ? lookup_table[x] : expensive_calc(x);
}
```

### 수학 연산 최적화

#### 1. 정수 연산 최적화

**비트 시프트 활용**:
```c
// 곱셈/나눗셈을 시프트로 대체
int multiply_by_8(int x) {
    return x << 3; // x * 8
}

int divide_by_4(int x) {
    return x >> 2; // x / 4
}

// 2의 거듭제곱 나머지 연산
int mod_power_of_2(int x, int n) {
    return x & (n - 1); // x % n (n이 2의 거듭제곱일 때)
}
```

**빠른 거듭제곱 알고리즘**:
```c
// O(log n) 거듭제곱
long long fast_power(long long base, int exp) {
    long long result = 1;
    while (exp > 0) {
        if (exp & 1) {
            result *= base;
        }
        base *= base;
        exp >>= 1;
    }
    return result;
}
```

#### 2. 부동소수점 최적화

**부동소수점 비교 최적화**:
```c
// 정확한 비교 (느림)
int float_equal_precise(float a, float b) {
    return fabs(a - b) < FLT_EPSILON;
}

// 빠른 근사 비교
int float_equal_fast(float a, float b) {
    union { float f; int i; } ua = {a}, ub = {b};
    return abs(ua.i - ub.i) <= 4; // ULP 기반 비교
}
```

### 컴파일러 최적화 활용

#### 1. 최적화 레벨 이해

**GCC 최적화 옵션**:
- **-O0**: 최적화 없음 (디버깅용)
- **-O1**: 기본 최적화 (컴파일 시간 단축)
- **-O2**: 권장 최적화 (속도와 크기 균형)
- **-O3**: 적극적 최적화 (최대 성능)
- **-Os**: 크기 최적화 (임베디드 시스템)
- **-Ofast**: 수학적 정확성 희생한 최고 성능

#### 2. 특정 최적화 옵션

**유용한 최적화 플래그**:
```bash
# 기본 권장 설정
gcc -O2 -march=native -mtune=native

# 공격적 최적화
gcc -O3 -march=native -mtune=native -funroll-loops -ffast-math

# 링크 타임 최적화
gcc -O2 -flto

# 프로파일 기반 최적화 (PGO)
gcc -O2 -fprofile-generate
./program < training_data
gcc -O2 -fprofile-use
```

#### 3. 컴파일러 내장 함수 활용

**SIMD 내장 함수**:
```c
#include <immintrin.h>

// 벡터화된 덧셈 (AVX2)
void vector_add(float* a, float* b, float* result, int n) {
    for (int i = 0; i < n; i += 8) {
        __m256 va = _mm256_load_ps(&a[i]);
        __m256 vb = _mm256_load_ps(&b[i]);
        __m256 vr = _mm256_add_ps(va, vb);
        _mm256_store_ps(&result[i], vr);
    }
}
```

**내장 함수 활용**:
```c
// 비트 카운팅
int count_bits(unsigned int x) {
    return __builtin_popcount(x);
}

// 선행 0 개수
int leading_zeros(unsigned int x) {
    return __builtin_clz(x);
}
```

### 성능 최적화 모범 사례

#### 1. 최적화 우선순위

1. **알고리즘 개선** (가장 높은 효과)
2. **데이터 구조 최적화**
3. **컴파일러 최적화 활용**
4. **루프 최적화**
5. **미시적 최적화** (가장 낮은 효과)

#### 2. 측정 기반 최적화

**지속적인 성능 모니터링**:
```c
// 성능 카운터 매크로
#define PERF_START() \
    struct timespec start, end; \
    clock_gettime(CLOCK_MONOTONIC, &start);

#define PERF_END(name) \
    clock_gettime(CLOCK_MONOTONIC, &end); \
    double elapsed = (end.tv_sec - start.tv_sec) + \
                    (end.tv_nsec - start.tv_nsec) / 1e9; \
    printf("%s: %.6f seconds\n", name, elapsed);
```

#### 3. 최적화 검증

**회귀 테스트**: 최적화 후 기능 정확성 확인
**성능 테스트**: 다양한 입력 크기로 성능 측정
**메모리 사용량**: 공간-시간 트레이드오프 분석

이러한 체계적인 성능 최적화 접근을 통해 C 프로그램의 성능을 크게 향상시킬 수 있습니다.