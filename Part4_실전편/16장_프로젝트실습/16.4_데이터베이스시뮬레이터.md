# 16.4 데이터베이스 시뮬레이터

> **"데이터베이스는 정보의 보물창고이다. 효율적인 저장과 검색 알고리즘은 현대 컴퓨팅의 핵심이다."**

## 개요

데이터베이스 시뮬레이터는 **관계형 데이터베이스의 핵심 기능**을 C언어로 구현하여 데이터 저장, 검색, 트랜잭션 처리의 원리를 이해하는 프로젝트입니다. DBMS의 내부 동작 메커니즘을 학습하고 고성능 데이터 처리 시스템을 구축하는 방법을 체계적으로 익힙니다.

### 학습 목표

1. **DBMS 아키텍처 이해**: 저장 엔진, 쿼리 프로세서, 트랜잭션 관리
2. **자료구조 활용**: B-트리, 해시 인덱스, 버퍼 풀 관리
3. **SQL 구현**: 파서, 옵티마이저, 실행 엔진 개발
4. **동시성 제어**: 락킹, MVCC, 트랜잭션 격리

## 데이터베이스 시스템 기본 개념

### DBMS 아키텍처

```
              데이터베이스 관리 시스템 (DBMS)
    ┌─────────────────────────────────────────────────────┐
    │                                                     │
    │  ┌─────────────────┐  ┌─────────────────────────┐  │
    │  │   SQL Parser    │  │     Query Optimizer     │  │
    │  │   구문 분석     │  │      쿼리 최적화        │  │
    │  └─────────────────┘  └─────────────────────────┘  │
    │            │                       │               │
    │  ┌─────────────────┐  ┌─────────────────────────┐  │
    │  │ Execution Engine│  │   Transaction Manager  │  │
    │  │    실행 엔진    │  │     트랜잭션 관리       │  │
    │  └─────────────────┘  └─────────────────────────┘  │
    │            │                       │               │
    │  ┌─────────────────┐  ┌─────────────────────────┐  │
    │  │ Storage Engine  │  │     Buffer Manager     │  │
    │  │   저장 엔진     │  │     버퍼 관리          │  │
    │  └─────────────────┘  └─────────────────────────┘  │
    │            │                       │               │
    │  ┌─────────────────┐  ┌─────────────────────────┐  │
    │  │   Index Manager │  │      Lock Manager      │  │
    │  │   인덱스 관리   │  │       락 관리          │  │
    │  └─────────────────┘  └─────────────────────────┘  │
    │                              │                     │
    │  ┌─────────────────────────────────────────────┐   │
    │  │            Physical Storage                 │   │
    │  │              물리적 저장소                   │   │
    │  └─────────────────────────────────────────────┘   │
    └─────────────────────────────────────────────────────┘
```

### 핵심 컴포넌트

#### 1. 테이블 구조
```c
typedef enum DataType {
    TYPE_INTEGER,
    TYPE_FLOAT,
    TYPE_STRING,
    TYPE_BOOLEAN,
    TYPE_DATE,
    TYPE_NULL
} DataType;

typedef struct Column {
    char name[64];
    DataType type;
    size_t size;
    bool is_primary_key;
    bool is_nullable;
    bool is_unique;
    char default_value[256];
} Column;

typedef struct Table {
    char name[64];
    Column* columns;
    int column_count;
    int row_count;
    size_t row_size;

    // 인덱스
    struct Index** indexes;
    int index_count;

    // 저장 정보
    int table_id;
    char* data_file_path;
    size_t file_size;
} Table;
```

#### 2. 레코드 관리
```c
typedef struct Record {
    int record_id;
    void* data;
    size_t data_size;
    bool is_deleted;
    time_t created_time;
    time_t modified_time;
} Record;

typedef struct Page {
    int page_id;
    char* data;
    size_t page_size;
    int record_count;
    int free_space;
    bool is_dirty;
    time_t last_access;
} Page;

// 페이지 내 레코드 슬롯 관리
typedef struct SlotDirectory {
    short* slots;        // 레코드 오프셋 배열
    int slot_count;
    int free_slots;
} SlotDirectory;
```

## 데이터베이스 시뮬레이터 설계

### 시스템 아키텍처

```c
typedef struct DatabaseSystem {
    // 메타데이터 관리
    Catalog* catalog;

    // 저장 관리
    StorageManager* storage;
    BufferManager* buffer_pool;

    // 쿼리 처리
    SQLParser* parser;
    QueryOptimizer* optimizer;
    ExecutionEngine* executor;

    // 트랜잭션 관리
    TransactionManager* transaction_mgr;
    LockManager* lock_mgr;
    LogManager* log_mgr;

    // 인덱스 관리
    IndexManager* index_mgr;

    // 시스템 설정
    DatabaseConfig* config;
} DatabaseSystem;
```

### 메타데이터 카탈로그

#### 시스템 테이블
```c
typedef struct Catalog {
    Table* tables_table;        // 테이블 메타데이터
    Table* columns_table;       // 컬럼 정보
    Table* indexes_table;       // 인덱스 정보
    Table* users_table;         // 사용자 정보
    Table* permissions_table;   // 권한 정보

    // 빠른 검색을 위한 해시맵
    HashMap* table_map;
    HashMap* index_map;
} Catalog;

// 테이블 생성 시 카탈로그 업데이트
int create_table(DatabaseSystem* db, const char* table_name,
                Column* columns, int column_count) {

    // 1. 테이블 구조 생성
    Table* table = malloc(sizeof(Table));
    strcpy(table->name, table_name);
    table->columns = columns;
    table->column_count = column_count;
    table->table_id = generate_table_id();

    // 2. 시스템 테이블에 메타데이터 저장
    insert_table_metadata(db->catalog->tables_table, table);

    for (int i = 0; i < column_count; i++) {
        insert_column_metadata(db->catalog->columns_table,
                              table->table_id, &columns[i]);
    }

    // 3. 해시맵에 등록
    hashmap_put(db->catalog->table_map, table_name, table);

    return SUCCESS;
}
```

## 핵심 구현 개념

### 1. 저장 관리자 (Storage Manager)

#### 페이지 기반 저장
```c
#define PAGE_SIZE 4096
#define PAGE_HEADER_SIZE 24

typedef struct PageHeader {
    int page_id;
    int table_id;
    short record_count;
    short free_space_offset;
    short free_space_size;
    int next_page_id;
    int prev_page_id;
    char checksum[8];
} PageHeader;

typedef struct StorageManager {
    FILE** data_files;
    int file_count;
    int max_files;

    // 페이지 캐시
    LRUCache* page_cache;

    // 여유 공간 관리
    FreeSpaceMap* free_space_map;

    // 동시성 제어
    pthread_rwlock_t storage_lock;
} StorageManager;

// 레코드 삽입
int insert_record(StorageManager* storage, int table_id, Record* record) {
    // 1. 적절한 페이지 찾기
    Page* page = find_page_with_space(storage, table_id, record->data_size);
    if (!page) {
        page = allocate_new_page(storage, table_id);
    }

    // 2. 페이지에 레코드 삽입
    int slot_id = insert_record_to_page(page, record);
    if (slot_id < 0) {
        return ERROR_PAGE_FULL;
    }

    // 3. 페이지를 더티로 마킹
    mark_page_dirty(storage, page);

    return slot_id;
}
```

#### 버퍼 풀 관리
```c
typedef struct BufferFrame {
    int page_id;
    char* data;
    bool is_dirty;
    bool is_pinned;
    int pin_count;
    time_t last_access;
    pthread_mutex_t frame_mutex;
} BufferFrame;

typedef struct BufferPool {
    BufferFrame* frames;
    int frame_count;
    int free_frames;

    // 교체 정책 (LRU)
    LRUList* lru_list;

    // 해시 테이블로 빠른 검색
    HashMap* page_table;

    // 동시성 제어
    pthread_rwlock_t buffer_lock;
} BufferPool;

// 페이지 요청 처리
BufferFrame* get_page(BufferPool* buffer_pool, int page_id) {
    pthread_rwlock_rdlock(&buffer_pool->buffer_lock);

    // 1. 버퍼에 이미 있는지 확인
    BufferFrame* frame = hashmap_get(buffer_pool->page_table, &page_id);
    if (frame) {
        frame->pin_count++;
        update_lru(buffer_pool->lru_list, frame);
        pthread_rwlock_unlock(&buffer_pool->buffer_lock);
        return frame;
    }

    pthread_rwlock_unlock(&buffer_pool->buffer_lock);
    pthread_rwlock_wrlock(&buffer_pool->buffer_lock);

    // 2. 버퍼에 없으면 디스크에서 로드
    frame = allocate_buffer_frame(buffer_pool);
    if (!frame) {
        frame = evict_lru_page(buffer_pool);
    }

    load_page_from_disk(frame, page_id);
    hashmap_put(buffer_pool->page_table, &page_id, frame);

    pthread_rwlock_unlock(&buffer_pool->buffer_lock);
    return frame;
}
```

### 2. 인덱스 관리

#### B+ 트리 구현
```c
#define BTREE_ORDER 256

typedef struct BTreeNode {
    bool is_leaf;
    int key_count;
    int keys[BTREE_ORDER - 1];
    void* values[BTREE_ORDER - 1];      // 리프 노드: 레코드 포인터
    struct BTreeNode* children[BTREE_ORDER];  // 내부 노드: 자식 포인터
    struct BTreeNode* next;              // 리프 노드 연결 리스트
    struct BTreeNode* parent;
} BTreeNode;

typedef struct BTreeIndex {
    BTreeNode* root;
    int height;
    int node_count;
    Column* indexed_column;

    // 통계 정보
    int distinct_values;
    int total_entries;

    // 동시성 제어
    pthread_rwlock_t index_lock;
} BTreeIndex;

// B+ 트리 검색
Record* btree_search(BTreeIndex* index, void* key) {
    pthread_rwlock_rdlock(&index->index_lock);

    BTreeNode* current = index->root;

    // 리프 노드까지 탐색
    while (!current->is_leaf) {
        int i = binary_search_keys(current->keys, current->key_count, key);
        current = current->children[i];
    }

    // 리프 노드에서 정확한 키 찾기
    int i = binary_search_keys(current->keys, current->key_count, key);
    Record* result = NULL;
    if (i < current->key_count && compare_keys(current->keys[i], key) == 0) {
        result = (Record*)current->values[i];
    }

    pthread_rwlock_unlock(&index->index_lock);
    return result;
}

// B+ 트리 삽입
int btree_insert(BTreeIndex* index, void* key, Record* record) {
    pthread_rwlock_wrlock(&index->index_lock);

    // 1. 삽입할 리프 노드 찾기
    BTreeNode* leaf = find_leaf_node(index->root, key);

    // 2. 리프 노드에 삽입
    int insert_result = insert_into_leaf(leaf, key, record);

    // 3. 노드 분할이 필요한 경우
    if (insert_result == NEED_SPLIT) {
        split_leaf_node(index, leaf);
    }

    pthread_rwlock_unlock(&index->index_lock);
    return SUCCESS;
}
```

#### 해시 인덱스
```c
typedef struct HashBucket {
    void* key;
    Record* record;
    struct HashBucket* next;
} HashBucket;

typedef struct HashIndex {
    HashBucket** buckets;
    int bucket_count;
    int total_entries;

    // 동적 크기 조정
    double load_factor;
    double max_load_factor;

    // 해시 함수
    uint32_t (*hash_function)(void* key, size_t key_size);

    pthread_rwlock_t hash_lock;
} HashIndex;

// 해시 테이블 검색 (O(1) 평균)
Record* hash_search(HashIndex* index, void* key, size_t key_size) {
    pthread_rwlock_rdlock(&index->hash_lock);

    uint32_t hash = index->hash_function(key, key_size);
    int bucket_index = hash % index->bucket_count;

    HashBucket* bucket = index->buckets[bucket_index];
    while (bucket) {
        if (compare_keys(bucket->key, key) == 0) {
            Record* result = bucket->record;
            pthread_rwlock_unlock(&index->hash_lock);
            return result;
        }
        bucket = bucket->next;
    }

    pthread_rwlock_unlock(&index->hash_lock);
    return NULL;
}

// 동적 해시 테이블 크기 조정
void resize_hash_table(HashIndex* index) {
    if (index->load_factor < index->max_load_factor) {
        return;
    }

    int old_bucket_count = index->bucket_count;
    HashBucket** old_buckets = index->buckets;

    // 크기 두 배로 증가
    index->bucket_count *= 2;
    index->buckets = calloc(index->bucket_count, sizeof(HashBucket*));

    // 모든 엔트리 재해시
    for (int i = 0; i < old_bucket_count; i++) {
        HashBucket* bucket = old_buckets[i];
        while (bucket) {
            HashBucket* next = bucket->next;
            rehash_entry(index, bucket);
            bucket = next;
        }
    }

    free(old_buckets);
}
```

### 3. SQL 파서 및 쿼리 처리

#### SQL 구문 분석
```c
typedef enum SQLStatementType {
    SQL_SELECT,
    SQL_INSERT,
    SQL_UPDATE,
    SQL_DELETE,
    SQL_CREATE_TABLE,
    SQL_DROP_TABLE,
    SQL_CREATE_INDEX
} SQLStatementType;

typedef struct SelectStatement {
    char** selected_columns;
    int column_count;
    char* table_name;
    Condition* where_clause;
    OrderBy* order_by;
    GroupBy* group_by;
    Having* having_clause;
    int limit;
    int offset;
} SelectStatement;

typedef struct Condition {
    enum { CONDITION_AND, CONDITION_OR, CONDITION_SIMPLE } type;

    union {
        struct {
            struct Condition* left;
            struct Condition* right;
        } compound;

        struct {
            char* column_name;
            enum { OP_EQ, OP_NE, OP_LT, OP_LE, OP_GT, OP_GE, OP_LIKE } operator;
            void* value;
            DataType value_type;
        } simple;
    };
} Condition;

// Lexer: SQL을 토큰으로 분해
typedef enum TokenType {
    TOKEN_SELECT, TOKEN_FROM, TOKEN_WHERE, TOKEN_INSERT,
    TOKEN_UPDATE, TOKEN_DELETE, TOKEN_CREATE, TOKEN_TABLE,
    TOKEN_IDENTIFIER, TOKEN_NUMBER, TOKEN_STRING,
    TOKEN_EQUALS, TOKEN_LESS_THAN, TOKEN_GREATER_THAN,
    TOKEN_SEMICOLON, TOKEN_COMMA, TOKEN_LEFT_PAREN, TOKEN_RIGHT_PAREN,
    TOKEN_EOF, TOKEN_ERROR
} TokenType;

typedef struct Token {
    TokenType type;
    char* value;
    int line;
    int column;
} Token;

typedef struct Lexer {
    char* input;
    int position;
    int line;
    int column;
    Token current_token;
} Lexer;

// Parser: 토큰을 구문 트리로 변환
typedef struct Parser {
    Lexer* lexer;
    Token current_token;
    DatabaseSystem* db;
} Parser;

SelectStatement* parse_select_statement(Parser* parser) {
    SelectStatement* stmt = malloc(sizeof(SelectStatement));

    // SELECT 키워드 확인
    expect_token(parser, TOKEN_SELECT);

    // 컬럼 목록 파싱
    stmt->selected_columns = parse_column_list(parser, &stmt->column_count);

    // FROM 절 파싱
    expect_token(parser, TOKEN_FROM);
    stmt->table_name = expect_identifier(parser);

    // WHERE 절 파싱 (선택적)
    if (current_token_is(parser, TOKEN_WHERE)) {
        advance_token(parser);
        stmt->where_clause = parse_condition(parser);
    }

    // ORDER BY 절 파싱 (선택적)
    if (current_token_is(parser, TOKEN_ORDER)) {
        stmt->order_by = parse_order_by(parser);
    }

    return stmt;
}
```

#### 쿼리 최적화
```c
typedef struct QueryPlan {
    enum { PLAN_SCAN, PLAN_INDEX_SCAN, PLAN_JOIN, PLAN_SORT } type;

    union {
        struct {
            Table* table;
            Condition* filter;
            double estimated_cost;
            int estimated_rows;
        } scan;

        struct {
            Table* table;
            Index* index;
            void* start_key;
            void* end_key;
            double estimated_cost;
            int estimated_rows;
        } index_scan;

        struct {
            struct QueryPlan* left;
            struct QueryPlan* right;
            enum { JOIN_NESTED_LOOP, JOIN_HASH, JOIN_MERGE } join_type;
            Condition* join_condition;
            double estimated_cost;
        } join;
    };
} QueryPlan;

typedef struct QueryOptimizer {
    CostModel* cost_model;
    Statistics* statistics;
} QueryOptimizer;

// 비용 기반 최적화
QueryPlan* optimize_query(QueryOptimizer* optimizer, SelectStatement* stmt) {
    // 1. 가능한 실행 계획들 생성
    QueryPlan** plans = generate_query_plans(stmt);
    int plan_count = count_plans(plans);

    // 2. 각 계획의 비용 계산
    double min_cost = INFINITY;
    QueryPlan* best_plan = NULL;

    for (int i = 0; i < plan_count; i++) {
        double cost = calculate_plan_cost(optimizer->cost_model, plans[i]);
        if (cost < min_cost) {
            min_cost = cost;
            best_plan = plans[i];
        }
    }

    // 3. 최적 계획 반환
    return best_plan;
}

// 통계 기반 비용 모델
double calculate_plan_cost(CostModel* model, QueryPlan* plan) {
    switch (plan->type) {
        case PLAN_SCAN:
            return model->seq_scan_cost * plan->scan.estimated_rows;

        case PLAN_INDEX_SCAN:
            return model->index_scan_cost * log2(plan->index_scan.estimated_rows);

        case PLAN_JOIN:
            double left_cost = calculate_plan_cost(model, plan->join.left);
            double right_cost = calculate_plan_cost(model, plan->join.right);

            if (plan->join.join_type == JOIN_NESTED_LOOP) {
                return left_cost + right_cost * plan->join.left->scan.estimated_rows;
            } else if (plan->join.join_type == JOIN_HASH) {
                return left_cost + right_cost +
                       model->hash_build_cost * plan->join.left->scan.estimated_rows;
            }
            break;
    }

    return 0.0;
}
```

### 4. 트랜잭션 관리

#### ACID 속성 구현
```c
typedef enum TransactionState {
    TX_ACTIVE,
    TX_COMMITTED,
    TX_ABORTED,
    TX_PREPARING
} TransactionState;

typedef struct Transaction {
    int transaction_id;
    TransactionState state;
    time_t start_time;
    time_t end_time;

    // 격리 수준
    enum { ISOLATION_READ_UNCOMMITTED, ISOLATION_READ_COMMITTED,
           ISOLATION_REPEATABLE_READ, ISOLATION_SERIALIZABLE } isolation_level;

    // 수정된 페이지 목록 (Undo용)
    PageList* modified_pages;

    // 보유 락 목록
    LockList* held_locks;

    // 로그 레코드
    LogSequenceNumber last_lsn;
} Transaction;

typedef struct TransactionManager {
    Transaction** active_transactions;
    int max_transactions;
    int next_transaction_id;

    // 트랜잭션 테이블
    HashMap* transaction_table;

    // 동시성 제어
    pthread_mutex_t tx_mgr_mutex;
} TransactionManager;

// 트랜잭션 시작
Transaction* begin_transaction(TransactionManager* tx_mgr) {
    pthread_mutex_lock(&tx_mgr->tx_mgr_mutex);

    Transaction* tx = malloc(sizeof(Transaction));
    tx->transaction_id = tx_mgr->next_transaction_id++;
    tx->state = TX_ACTIVE;
    tx->start_time = time(NULL);
    tx->modified_pages = create_page_list();
    tx->held_locks = create_lock_list();

    hashmap_put(tx_mgr->transaction_table, &tx->transaction_id, tx);

    pthread_mutex_unlock(&tx_mgr->tx_mgr_mutex);

    // BEGIN 로그 레코드 작성
    write_log_record(LOG_BEGIN, tx->transaction_id, 0, NULL, NULL);

    return tx;
}

// 트랜잭션 커밋
int commit_transaction(TransactionManager* tx_mgr, Transaction* tx) {
    // 1. 커밋 로그 레코드 작성
    LogSequenceNumber commit_lsn = write_log_record(LOG_COMMIT,
                                                   tx->transaction_id, 0, NULL, NULL);

    // 2. 로그를 디스크에 강제 플러시 (WAL)
    force_log_to_disk(commit_lsn);

    // 3. 더티 페이지를 디스크에 쓰기
    flush_dirty_pages(tx->modified_pages);

    // 4. 락 해제
    release_all_locks(tx_mgr->lock_mgr, tx);

    // 5. 트랜잭션 상태 변경
    tx->state = TX_COMMITTED;
    tx->end_time = time(NULL);

    return SUCCESS;
}
```

#### 동시성 제어 (2PL)
```c
typedef enum LockType {
    LOCK_SHARED,
    LOCK_EXCLUSIVE,
    LOCK_INTENTION_SHARED,
    LOCK_INTENTION_EXCLUSIVE
} LockType;

typedef struct Lock {
    int transaction_id;
    LockType type;
    void* resource;          // 테이블, 페이지, 레코드
    enum { RESOURCE_TABLE, RESOURCE_PAGE, RESOURCE_RECORD } resource_type;
    struct Lock* next;
} Lock;

typedef struct LockManager {
    HashMap* lock_table;     // 리소스 → 락 리스트
    HashMap* wait_graph;     // 데드락 탐지용

    pthread_mutex_t lock_mgr_mutex;
    pthread_cond_t lock_available;
} LockManager;

// 락 획득
int acquire_lock(LockManager* lock_mgr, Transaction* tx,
                void* resource, LockType type) {
    pthread_mutex_lock(&lock_mgr->lock_mgr_mutex);

    // 1. 기존 락 확인
    Lock* existing_locks = hashmap_get(lock_mgr->lock_table, resource);

    // 2. 락 호환성 검사
    if (!is_lock_compatible(existing_locks, type)) {
        // 3. 대기 (데드락 탐지 포함)
        if (would_cause_deadlock(lock_mgr, tx, resource)) {
            pthread_mutex_unlock(&lock_mgr->lock_mgr_mutex);
            return ERROR_DEADLOCK;
        }

        // 대기 큐에 추가
        add_to_wait_queue(lock_mgr, tx, resource, type);

        while (!can_grant_lock(lock_mgr, tx, resource, type)) {
            pthread_cond_wait(&lock_mgr->lock_available, &lock_mgr->lock_mgr_mutex);
        }
    }

    // 4. 락 부여
    Lock* new_lock = create_lock(tx->transaction_id, type, resource);
    add_lock_to_table(lock_mgr, resource, new_lock);
    add_lock_to_transaction(tx, new_lock);

    pthread_mutex_unlock(&lock_mgr->lock_mgr_mutex);
    return SUCCESS;
}

// 데드락 탐지 (사이클 검출)
bool would_cause_deadlock(LockManager* lock_mgr, Transaction* tx, void* resource) {
    // 대기 그래프 구축
    WaitGraph* graph = build_wait_graph(lock_mgr);

    // DFS로 사이클 탐지
    bool has_cycle = detect_cycle_dfs(graph, tx->transaction_id);

    free_wait_graph(graph);
    return has_cycle;
}
```

#### WAL (Write-Ahead Logging)
```c
typedef enum LogRecordType {
    LOG_BEGIN,
    LOG_COMMIT,
    LOG_ABORT,
    LOG_UPDATE,
    LOG_INSERT,
    LOG_DELETE,
    LOG_CHECKPOINT
} LogRecordType;

typedef struct LogRecord {
    LogSequenceNumber lsn;
    LogRecordType type;
    int transaction_id;
    int page_id;
    size_t data_size;
    void* before_image;      // Undo용
    void* after_image;       // Redo용
    LogSequenceNumber prev_lsn;  // 같은 트랜잭션의 이전 LSN
} LogRecord;

typedef struct LogManager {
    FILE* log_file;
    LogSequenceNumber next_lsn;
    char* log_buffer;
    size_t buffer_size;
    size_t buffer_offset;

    pthread_mutex_t log_mutex;
} LogManager;

// 로그 레코드 작성
LogSequenceNumber write_log_record(LogRecordType type, int tx_id,
                                  int page_id, void* before, void* after) {
    LogManager* log_mgr = get_log_manager();

    pthread_mutex_lock(&log_mgr->log_mutex);

    // 1. LSN 할당
    LogSequenceNumber lsn = log_mgr->next_lsn++;

    // 2. 로그 레코드 구성
    LogRecord record = {
        .lsn = lsn,
        .type = type,
        .transaction_id = tx_id,
        .page_id = page_id,
        .before_image = before,
        .after_image = after
    };

    // 3. 로그 버퍼에 추가
    append_to_log_buffer(log_mgr, &record);

    // 4. 버퍼가 가득 차면 플러시
    if (log_mgr->buffer_offset >= log_mgr->buffer_size * 0.8) {
        flush_log_buffer(log_mgr);
    }

    pthread_mutex_unlock(&log_mgr->log_mutex);
    return lsn;
}

// 복구 처리 (ARIES 알고리즘)
void perform_recovery(DatabaseSystem* db) {
    LogManager* log_mgr = db->log_mgr;

    // Phase 1: Analysis - 체크포인트부터 로그 끝까지 분석
    CheckpointInfo* checkpoint = find_latest_checkpoint();
    TransactionTable* tx_table = analyze_log(log_mgr, checkpoint);

    // Phase 2: Redo - 커밋된 트랜잭션의 변경사항 재적용
    redo_phase(log_mgr, tx_table, checkpoint->redo_lsn);

    // Phase 3: Undo - 중단된 트랜잭션의 변경사항 취소
    undo_phase(log_mgr, tx_table);

    // 복구 완료 로그 작성
    write_log_record(LOG_RECOVERY_COMPLETE, 0, 0, NULL, NULL);
}
```

### 5. 통계 및 비용 모델

#### 테이블 통계
```c
typedef struct TableStatistics {
    char table_name[64];
    int total_rows;
    int total_pages;
    double average_row_size;

    // 컬럼별 통계
    ColumnStatistics* column_stats;
    int column_count;

    // 갱신 정보
    time_t last_analyzed;
    int rows_inserted_since_analyze;
    int rows_deleted_since_analyze;
} TableStatistics;

typedef struct ColumnStatistics {
    char column_name[64];
    int distinct_values;     // 카디널리티
    int null_count;
    void* min_value;
    void* max_value;

    // 히스토그램 (등높이 히스토그램)
    Histogram* histogram;

    // 최빈값들
    FrequentValues* frequent_values;
} ColumnStatistics;

typedef struct Histogram {
    HistogramBucket* buckets;
    int bucket_count;
} Histogram;

typedef struct HistogramBucket {
    void* range_start;
    void* range_end;
    int frequency;
    int distinct_values;
} HistogramBucket;

// 선택도 추정
double estimate_selectivity(ColumnStatistics* stats, Condition* condition) {
    switch (condition->simple.operator) {
        case OP_EQ:
            // 등값 조건: 1 / distinct_values
            return 1.0 / stats->distinct_values;

        case OP_LT:
        case OP_LE:
            // 범위 조건: 히스토그램 사용
            return estimate_range_selectivity(stats->histogram,
                                            NULL, condition->simple.value);

        case OP_GT:
        case OP_GE:
            return estimate_range_selectivity(stats->histogram,
                                            condition->simple.value, NULL);

        case OP_LIKE:
            // 패턴 매칭: 대략적 추정
            return estimate_like_selectivity(condition->simple.value);
    }

    return 0.1;  // 기본값
}

// 결과 크기 추정
int estimate_result_size(TableStatistics* table_stats, Condition* where_clause) {
    if (!where_clause) {
        return table_stats->total_rows;
    }

    double selectivity = calculate_condition_selectivity(table_stats, where_clause);
    return (int)(table_stats->total_rows * selectivity);
}
```

#### 적응형 쿼리 최적화
```c
typedef struct ExecutionStatistics {
    QueryPlan* plan;
    double actual_execution_time;
    int actual_rows_processed;
    int actual_io_operations;
    time_t execution_time;
} ExecutionStatistics;

typedef struct AdaptiveOptimizer {
    HashMap* execution_history;  // 쿼리 → 실행 통계 목록
    CostModel* cost_model;

    // 학습 매개변수
    double learning_rate;
    int min_executions_for_update;
} AdaptiveOptimizer;

// 실행 결과를 바탕으로 비용 모델 조정
void update_cost_model(AdaptiveOptimizer* optimizer,
                      ExecutionStatistics* exec_stats) {

    QueryPlan* plan = exec_stats->plan;
    double predicted_cost = calculate_plan_cost(optimizer->cost_model, plan);
    double actual_cost = exec_stats->actual_execution_time;

    // 오차 계산
    double error = actual_cost - predicted_cost;
    double error_ratio = error / predicted_cost;

    // 비용 모델 매개변수 조정 (경사하강법)
    if (fabs(error_ratio) > 0.1) {  // 10% 이상 오차
        adjust_cost_parameters(optimizer->cost_model, plan, error_ratio);
    }

    // 실행 통계 저장
    store_execution_statistics(optimizer, exec_stats);
}

// 매개변수 조정
void adjust_cost_parameters(CostModel* model, QueryPlan* plan, double error_ratio) {
    double adjustment = model->learning_rate * error_ratio;

    switch (plan->type) {
        case PLAN_SCAN:
            model->seq_scan_cost *= (1.0 + adjustment);
            break;

        case PLAN_INDEX_SCAN:
            model->index_scan_cost *= (1.0 + adjustment);
            break;

        case PLAN_JOIN:
            if (plan->join.join_type == JOIN_HASH) {
                model->hash_join_cost *= (1.0 + adjustment);
            } else if (plan->join.join_type == JOIN_NESTED_LOOP) {
                model->nested_loop_cost *= (1.0 + adjustment);
            }
            break;
    }
}
```

## 고급 기능

### 1. 분산 데이터베이스

#### 샤딩 (Sharding)
```c
typedef struct ShardingStrategy {
    enum { SHARD_HASH, SHARD_RANGE, SHARD_DIRECTORY } type;

    union {
        struct {
            char* shard_key_column;
            int shard_count;
            uint32_t (*hash_function)(void* key);
        } hash_sharding;

        struct {
            char* shard_key_column;
            RangeBoundary* ranges;
            int range_count;
        } range_sharding;

        struct {
            HashMap* shard_directory;  // 키 → 샤드 매핑
        } directory_sharding;
    };
} ShardingStrategy;

typedef struct Shard {
    int shard_id;
    char* host;
    int port;
    DatabaseSystem* local_db;
    bool is_local;
} Shard;

typedef struct DistributedDatabase {
    Shard* shards;
    int shard_count;
    ShardingStrategy* sharding_strategy;

    // 분산 트랜잭션 관리
    DistributedTransactionManager* dist_tx_mgr;
} DistributedDatabase;

// 샤드 라우팅
Shard* route_to_shard(DistributedDatabase* dist_db, void* shard_key) {
    ShardingStrategy* strategy = dist_db->sharding_strategy;

    switch (strategy->type) {
        case SHARD_HASH: {
            uint32_t hash = strategy->hash_sharding.hash_function(shard_key);
            int shard_id = hash % strategy->hash_sharding.shard_count;
            return &dist_db->shards[shard_id];
        }

        case SHARD_RANGE: {
            for (int i = 0; i < strategy->range_sharding.range_count; i++) {
                RangeBoundary* range = &strategy->range_sharding.ranges[i];
                if (key_in_range(shard_key, range)) {
                    return &dist_db->shards[i];
                }
            }
            break;
        }

        case SHARD_DIRECTORY: {
            Shard* shard = hashmap_get(strategy->directory_sharding.shard_directory,
                                      shard_key);
            return shard;
        }
    }

    return NULL;
}
```

#### 2PC (Two-Phase Commit)
```c
typedef enum TwoPCPhase {
    PHASE_PREPARE,
    PHASE_COMMIT,
    PHASE_ABORT
} TwoPCPhase;

typedef struct DistributedTransaction {
    int global_transaction_id;
    Transaction** local_transactions;
    Shard* coordinator;
    Shard** participants;
    int participant_count;

    TwoPCPhase current_phase;
    bool* participant_votes;    // PREPARE 응답
    bool* participant_acks;     // COMMIT/ABORT 응답
} DistributedTransaction;

// 분산 트랜잭션 커밋 (코디네이터)
int commit_distributed_transaction(DistributedTransaction* dist_tx) {
    // Phase 1: Prepare
    bool all_prepared = true;
    for (int i = 0; i < dist_tx->participant_count; i++) {
        if (!send_prepare_message(dist_tx->participants[i],
                                 dist_tx->global_transaction_id)) {
            all_prepared = false;
            break;
        }
    }

    // Phase 2: Commit or Abort
    if (all_prepared) {
        // 모든 참여자가 준비됨 → 커밋
        for (int i = 0; i < dist_tx->participant_count; i++) {
            send_commit_message(dist_tx->participants[i],
                               dist_tx->global_transaction_id);
        }
        return SUCCESS;
    } else {
        // 일부 참여자가 실패 → 중단
        for (int i = 0; i < dist_tx->participant_count; i++) {
            send_abort_message(dist_tx->participants[i],
                              dist_tx->global_transaction_id);
        }
        return ERROR_TRANSACTION_ABORTED;
    }
}
```

### 2. 실시간 분석 (OLAP)

#### 컬럼 저장 형식
```c
typedef struct ColumnStore {
    char column_name[64];
    DataType data_type;
    void** data_blocks;      // 압축된 데이터 블록들
    int block_count;

    // 압축 정보
    enum { COMPRESS_NONE, COMPRESS_RLE, COMPRESS_DELTA,
           COMPRESS_DICTIONARY } compression_type;

    // 인덱스
    BitmapIndex* bitmap_index;
    ZoneMap* zone_map;
} ColumnStore;

typedef struct BitmapIndex {
    void* distinct_values;
    Bitmap** bitmaps;        // 각 값에 대한 비트맵
    int value_count;
} BitmapIndex;

// Run-Length Encoding 압축
typedef struct RLEBlock {
    void* value;
    int run_length;
} RLEBlock;

void* compress_column_rle(void* data, int row_count, DataType type,
                         size_t* compressed_size) {
    RLEBlock* blocks = malloc(row_count * sizeof(RLEBlock));
    int block_count = 0;

    void* current_value = get_value_at(data, 0, type);
    int current_run = 1;

    for (int i = 1; i < row_count; i++) {
        void* value = get_value_at(data, i, type);

        if (compare_values(current_value, value, type) == 0) {
            current_run++;
        } else {
            // 현재 run 저장
            blocks[block_count].value = current_value;
            blocks[block_count].run_length = current_run;
            block_count++;

            // 새로운 run 시작
            current_value = value;
            current_run = 1;
        }
    }

    // 마지막 run 저장
    blocks[block_count].value = current_value;
    blocks[block_count].run_length = current_run;
    block_count++;

    *compressed_size = block_count * sizeof(RLEBlock);
    return blocks;
}
```

#### OLAP 쿼리 처리
```c
typedef struct OLAPQuery {
    char** dimensions;       // 차원 (GROUP BY)
    int dimension_count;

    char** measures;         // 측정값 (집계 함수)
    AggregateFunction* aggregates;
    int measure_count;

    Condition* filters;      // WHERE 조건

    // OLAP 연산
    bool rollup;
    bool cube;
    char** drill_down_path;
} OLAPQuery;

typedef enum AggregateFunction {
    AGG_SUM, AGG_COUNT, AGG_AVG, AGG_MIN, AGG_MAX,
    AGG_COUNT_DISTINCT, AGG_MEDIAN, AGG_STDDEV
} AggregateFunction;

// 비트맵 인덱스를 이용한 빠른 필터링
Bitmap* execute_olap_filter(ColumnStore** columns, Condition* condition) {
    Bitmap* result = NULL;

    if (condition->type == CONDITION_SIMPLE) {
        // 단일 조건
        ColumnStore* column = find_column(columns, condition->simple.column_name);
        result = bitmap_index_lookup(column->bitmap_index,
                                   condition->simple.value);

    } else if (condition->type == CONDITION_AND) {
        // AND 조건
        Bitmap* left = execute_olap_filter(columns, condition->compound.left);
        Bitmap* right = execute_olap_filter(columns, condition->compound.right);
        result = bitmap_and(left, right);

    } else if (condition->type == CONDITION_OR) {
        // OR 조건
        Bitmap* left = execute_olap_filter(columns, condition->compound.left);
        Bitmap* right = execute_olap_filter(columns, condition->compound.right);
        result = bitmap_or(left, right);
    }

    return result;
}

// 병렬 집계 처리
typedef struct AggregationTask {
    ColumnStore* measure_column;
    Bitmap* filter_bitmap;
    AggregateFunction function;
    int start_row;
    int end_row;
    double result;
} AggregationTask;

void* parallel_aggregation_worker(void* arg) {
    AggregationTask* task = (AggregationTask*)arg;

    double accumulator = 0.0;
    int count = 0;

    for (int i = task->start_row; i < task->end_row; i++) {
        if (bitmap_test(task->filter_bitmap, i)) {
            double value = get_column_value(task->measure_column, i);

            switch (task->function) {
                case AGG_SUM:
                case AGG_AVG:
                    accumulator += value;
                    count++;
                    break;
                case AGG_COUNT:
                    count++;
                    break;
                case AGG_MIN:
                    if (count == 0 || value < accumulator) {
                        accumulator = value;
                    }
                    count++;
                    break;
                case AGG_MAX:
                    if (count == 0 || value > accumulator) {
                        accumulator = value;
                    }
                    count++;
                    break;
            }
        }
    }

    if (task->function == AGG_AVG && count > 0) {
        task->result = accumulator / count;
    } else {
        task->result = (task->function == AGG_COUNT) ? count : accumulator;
    }

    return NULL;
}
```

### 3. 메모리 데이터베이스 최적화

#### 캐시 친화적 자료구조
```c
// 캐시 라인 크기에 맞춘 B+ 트리 노드
#define CACHE_LINE_SIZE 64
#define BTREE_NODE_SIZE (CACHE_LINE_SIZE * 4)  // 256 바이트

typedef struct CacheOptimizedBTreeNode {
    uint16_t key_count;
    uint8_t is_leaf;
    uint8_t padding[1];

    // 키들을 연속된 메모리에 배치
    int keys[60];           // 240 바이트

    // 리프 노드: 값들, 내부 노드: 자식 포인터들
    union {
        void* values[60];
        struct CacheOptimizedBTreeNode* children[61];
    };
} __attribute__((aligned(CACHE_LINE_SIZE))) CacheOptimizedBTreeNode;

// SIMD를 활용한 배열 검색
int simd_binary_search(int* array, int size, int target) {
    // AVX2를 사용한 병렬 비교
    __m256i target_vec = _mm256_set1_epi32(target);

    for (int i = 0; i < size; i += 8) {
        __m256i data_vec = _mm256_load_si256((__m256i*)(array + i));
        __m256i cmp_result = _mm256_cmpeq_epi32(data_vec, target_vec);

        int mask = _mm256_movemask_epi8(cmp_result);
        if (mask != 0) {
            // 정확한 위치 찾기
            for (int j = 0; j < 8; j++) {
                if (array[i + j] == target) {
                    return i + j;
                }
            }
        }
    }

    return -1;  // 찾지 못함
}
```

#### 메모리 풀 최적화
```c
typedef struct MemoryPool {
    void* memory_block;
    size_t block_size;
    size_t chunk_size;

    // 자유 리스트 (스택 구조)
    void** free_list;
    int free_count;
    int total_chunks;

    // 스레드 안전성
    pthread_spinlock_t spinlock;

    // 통계
    atomic_int allocations;
    atomic_int deallocations;
} MemoryPool;

// 락-프리 메모리 풀 (Per-thread)
typedef struct ThreadLocalPool {
    MemoryPool* local_pool;
    MemoryPool* global_pool;
    int thread_id;

    // 배치 할당/해제
    void** batch_buffer;
    int batch_size;
    int batch_count;
} ThreadLocalPool;

void* fast_alloc(ThreadLocalPool* tl_pool) {
    // 1. 로컬 풀에서 할당 시도
    if (tl_pool->local_pool->free_count > 0) {
        return memory_pool_alloc(tl_pool->local_pool);
    }

    // 2. 글로벌 풀에서 배치로 가져오기
    if (batch_refill(tl_pool) > 0) {
        return memory_pool_alloc(tl_pool->local_pool);
    }

    // 3. 시스템에서 새로운 메모리 할당
    return malloc(tl_pool->local_pool->chunk_size);
}

int batch_refill(ThreadLocalPool* tl_pool) {
    const int BATCH_SIZE = 64;
    void* batch[BATCH_SIZE];

    int obtained = memory_pool_alloc_batch(tl_pool->global_pool,
                                          batch, BATCH_SIZE);

    for (int i = 0; i < obtained; i++) {
        memory_pool_free(tl_pool->local_pool, batch[i]);
    }

    return obtained;
}
```

## 실전 적용 사례

### 1. 소규모 애플리케이션용 임베디드 DB

#### SQLite 스타일 구현
```c
typedef struct EmbeddedDB {
    char* db_file_path;
    FILE* db_file;

    // 단순한 페이지 관리
    Page* page_cache;
    int cache_size;

    // 트랜잭션 (단일 Writer)
    Transaction* current_transaction;
    bool auto_commit;

    // 간단한 인덱스
    HashMap* table_indexes;
} EmbeddedDB;

// 단순화된 SQL 실행
int execute_sql(EmbeddedDB* db, const char* sql) {
    // 1. 간단한 파싱 (키워드 기반)
    SQLStatement stmt = simple_parse(sql);

    // 2. 트랜잭션 자동 시작
    if (db->auto_commit && !db->current_transaction) {
        db->current_transaction = begin_simple_transaction(db);
    }

    // 3. 실행
    int result = execute_simple_statement(db, &stmt);

    // 4. 자동 커밋
    if (db->auto_commit && result == SUCCESS) {
        commit_simple_transaction(db, db->current_transaction);
        db->current_transaction = NULL;
    }

    return result;
}
```

### 2. 웹 애플리케이션용 캐시 DB

#### Redis 스타일 키-값 저장소
```c
typedef struct CacheDB {
    // 메인 해시 테이블
    HashMap* main_dict;

    // 만료 시간 관리
    HashMap* expire_dict;

    // 메모리 관리
    size_t used_memory;
    size_t max_memory;

    // LRU 교체 정책
    LRUCache* lru_cache;

    // 영속성 (선택적)
    AOFWriter* aof_writer;
    RDBSnapshot* rdb_snapshot;
} CacheDB;

typedef struct CacheValue {
    enum { CACHE_STRING, CACHE_LIST, CACHE_SET,
           CACHE_HASH, CACHE_ZSET } type;

    union {
        char* string_value;
        List* list_value;
        HashSet* set_value;
        HashMap* hash_value;
        ZSet* zset_value;
    };

    time_t expire_time;
    size_t memory_usage;
} CacheValue;

// Redis-like 명령어 처리
int cache_set(CacheDB* cache, const char* key, const char* value, int ttl) {
    // 1. 기존 값 확인 및 메모리 정리
    CacheValue* old_value = hashmap_get(cache->main_dict, key);
    if (old_value) {
        cache->used_memory -= old_value->memory_usage;
        free_cache_value(old_value);
    }

    // 2. 새 값 생성
    CacheValue* new_value = create_string_value(value);
    new_value->memory_usage = sizeof(CacheValue) + strlen(value) + 1;

    // 3. 만료 시간 설정
    if (ttl > 0) {
        new_value->expire_time = time(NULL) + ttl;
        hashmap_put(cache->expire_dict, key, &new_value->expire_time);
    }

    // 4. 메모리 체크 및 교체
    cache->used_memory += new_value->memory_usage;
    if (cache->used_memory > cache->max_memory) {
        evict_lru_keys(cache);
    }

    // 5. 저장
    hashmap_put(cache->main_dict, key, new_value);
    lru_cache_touch(cache->lru_cache, key);

    // 6. AOF 로깅
    if (cache->aof_writer) {
        aof_write_command(cache->aof_writer, "SET", key, value);
    }

    return SUCCESS;
}
```

### 3. 고성능 OLTP 시스템

#### 최적화된 트랜잭션 처리
```c
typedef struct HighPerformanceDB {
    // 멀티버전 동시성 제어
    MVCCManager* mvcc_manager;

    // 파티셔닝된 저장소
    PartitionedStorage* partitioned_storage;

    // 연결 풀링
    ConnectionPool* connection_pool;

    // 쿼리 플랜 캐시
    PlanCache* plan_cache;

    // 배치 커밋
    BatchCommitManager* batch_commit_mgr;

    // 성능 모니터링
    PerformanceMonitor* perf_monitor;
} HighPerformanceDB;

// MVCC를 이용한 무락 읽기
Record* mvcc_read(MVCCManager* mvcc, int table_id, int record_id,
                 Transaction* tx) {

    RecordVersion* versions = get_record_versions(mvcc, table_id, record_id);

    // 트랜잭션 시작 시점에서 볼 수 있는 최신 버전 찾기
    RecordVersion* visible_version = NULL;

    for (RecordVersion* version = versions; version; version = version->next) {
        if (version->created_tx_id <= tx->start_timestamp &&
            (version->deleted_tx_id == 0 ||
             version->deleted_tx_id > tx->start_timestamp)) {

            visible_version = version;
            break;
        }
    }

    return visible_version ? visible_version->record : NULL;
}

// 배치 커밋으로 I/O 최적화
typedef struct BatchCommitGroup {
    Transaction** transactions;
    int tx_count;
    int max_tx_count;

    LogSequenceNumber group_commit_lsn;
    pthread_cond_t commit_complete;
    pthread_mutex_t group_mutex;
} BatchCommitGroup;

void batch_commit_worker(BatchCommitManager* batch_mgr) {
    while (batch_mgr->running) {
        BatchCommitGroup* group = wait_for_commit_group(batch_mgr);

        if (group->tx_count > 0) {
            // 1. 모든 트랜잭션의 로그를 한 번에 플러시
            LogSequenceNumber max_lsn = 0;
            for (int i = 0; i < group->tx_count; i++) {
                if (group->transactions[i]->last_lsn > max_lsn) {
                    max_lsn = group->transactions[i]->last_lsn;
                }
            }

            force_log_to_disk(max_lsn);

            // 2. 모든 트랜잭션을 커밋 상태로 변경
            for (int i = 0; i < group->tx_count; i++) {
                group->transactions[i]->state = TX_COMMITTED;
            }

            // 3. 대기 중인 스레드들에게 알림
            pthread_cond_broadcast(&group->commit_complete);
        }
    }
}
```

## 모범 사례 및 주의사항

### 성능 최적화 원칙

1. **데이터 지역성**: 관련 데이터를 가까이 배치하여 캐시 성능 향상
2. **인덱스 전략**: 쿼리 패턴에 맞는 인덱스 설계
3. **배치 처리**: I/O 작업을 그룹화하여 처리량 향상
4. **비동기 처리**: 블로킹 작업을 백그라운드로 이동
5. **메모리 관리**: 풀링과 재사용으로 할당 오버헤드 최소화

### 안정성 보장

#### 데이터 무결성
```c
// 체크포인트와 WAL을 이용한 내구성 보장
typedef struct DurabilityManager {
    WALWriter* wal_writer;
    CheckpointManager* checkpoint_mgr;

    // 설정 가능한 내구성 수준
    enum { DURABILITY_NONE, DURABILITY_MEMORY,
           DURABILITY_LOCAL, DURABILITY_REMOTE } durability_level;
} DurabilityManager;

int ensure_durability(DurabilityManager* dur_mgr, Transaction* tx) {
    switch (dur_mgr->durability_level) {
        case DURABILITY_MEMORY:
            // 메모리 배리어만 사용
            memory_barrier();
            break;

        case DURABILITY_LOCAL:
            // 로컬 디스크에 동기적 쓰기
            force_log_to_disk(tx->last_lsn);
            break;

        case DURABILITY_REMOTE:
            // 원격 복제본에도 전송
            replicate_log_records(tx->log_records);
            break;
    }

    return SUCCESS;
}
```

#### 오류 복구
```c
// 자동 복구 시스템
typedef struct AutoRecoverySystem {
    HealthChecker* health_checker;
    FailureDetector* failure_detector;
    RecoveryManager* recovery_manager;

    // 복구 정책
    int max_retry_attempts;
    int retry_delay_ms;
    bool auto_restart_on_failure;
} AutoRecoverySystem;

void monitor_system_health(AutoRecoverySystem* recovery_sys) {
    while (recovery_sys->running) {
        SystemHealth health = check_system_health(recovery_sys->health_checker);

        if (health.status == HEALTH_CRITICAL) {
            // 심각한 오류 → 자동 복구 시도
            RecoveryAction action = determine_recovery_action(health);

            switch (action.type) {
                case RECOVERY_RESTART_TRANSACTION:
                    restart_failed_transaction(action.transaction_id);
                    break;

                case RECOVERY_REBUILD_INDEX:
                    rebuild_corrupted_index(action.index_id);
                    break;

                case RECOVERY_RESTORE_FROM_BACKUP:
                    restore_from_backup(action.backup_timestamp);
                    break;

                case RECOVERY_FAILOVER:
                    failover_to_replica(action.replica_id);
                    break;
            }
        }

        sleep_ms(recovery_sys->health_check_interval);
    }
}
```

## 마무리

데이터베이스 시뮬레이터 개발을 통해 학습한 내용:

### 핵심 개념
- **DBMS 아키텍처**: 저장 엔진, 쿼리 처리기, 트랜잭션 관리자
- **자료구조와 알고리즘**: B+ 트리, 해시 인덱스, 버퍼 관리
- **동시성 제어**: 락킹, MVCC, 트랜잭션 격리
- **성능 최적화**: 쿼리 최적화, 인덱싱, 캐싱

### 실무 역량
- **시스템 설계**: 확장 가능하고 안정적인 데이터베이스 아키텍처
- **알고리즘 구현**: 효율적인 검색, 정렬, 집계 알고리즘
- **성능 튜닝**: 병목 지점 분석과 최적화 기법
- **장애 대응**: 복구 메커니즘과 고가용성 구현

이러한 지식을 바탕으로 실제 데이터베이스 시스템을 이해하고, 애플리케이션의 데이터 처리 성능을 향상시키는 데 활용할 수 있습니다.